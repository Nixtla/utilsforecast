{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bbcfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622bc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deven367/miniforge3/envs/nixtla/lib/python3.11/site-packages/nbdev/doclinks.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources,importlib\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "from execnb.nbio import read_nb\n",
    "from nbdev.processors import NBProcessor\n",
    "from nbdev.export import ExportModuleProc, nb_export\n",
    "from nbdev.maker import ModuleMaker\n",
    "from fastcore.xtras import globtastic, Path\n",
    "from functools import partial\n",
    "from fastcore.script import call_parse\n",
    "from nbdev import nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_path = \"../nbs/evaluation.ipynb\"\n",
    "nb = read_nb(nb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "tst_flags = 'datasets distributed matplotlib polars pyarrow scipy'.split()\n",
    "to_skip = [\n",
    "    'showdoc',\n",
    "    'load_ext',\n",
    "    'from nbdev'\n",
    "]\n",
    "\n",
    "\n",
    "def print_execs(cell):\n",
    "    if 'exec' in cell.source: print(cell.source)\n",
    "\n",
    "def print_hide(cell):\n",
    "    if 'hide' in cell.directives_: print(cell.source)\n",
    "\n",
    "def other_tests(cell):\n",
    "    if len(cell.directives_) == 0:\n",
    "        print(cell.source)\n",
    "\n",
    "def get_markdown(cell):\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        print(cell.source)\n",
    "\n",
    "def extract_dir(cell, dir):\n",
    "    if dir in cell.directives_:\n",
    "        print(cell.source)\n",
    "\n",
    "def no_dir_and_dir(cell, dir):\n",
    "    if len(cell.directives_) == 0:\n",
    "        print(cell.source)\n",
    "\n",
    "    if dir in cell.directives_:\n",
    "        print(cell.source)\n",
    "\n",
    "def get_all_tests2(cell):\n",
    "    if cell.cell_type == \"code\":\n",
    "\n",
    "        if len(cell.directives_) == 0:\n",
    "            print(cell.source)\n",
    "\n",
    "\n",
    "        elif any(x in tst_flags + ['hide'] for x in cell.directives_):\n",
    "            if not (x in cell.source for x in to_skip):\n",
    "                print(cell.source)\n",
    "\n",
    "def get_all_tests(cell):\n",
    "    if len(cell.directives_) == 0:\n",
    "        print(cell.source)\n",
    "\n",
    "    if any(x in tst_flags + [\"hide\"] for x in cell.directives_):\n",
    "        print(cell.source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e5bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_cell = nb.cells[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8942a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{ 'cell_type': 'code',\n",
       "  'execution_count': None,\n",
       "  'id': '5aace6e9-4c24-4e66-b786-f468e32227a6',\n",
       "  'idx_': 0,\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': '#| hide\\n%load_ext autoreload\\n%autoreload 2'}\n",
       "```"
      ],
      "text/plain": [
       "{'cell_type': 'code',\n",
       " 'execution_count': None,\n",
       " 'id': '5aace6e9-4c24-4e66-b786-f468e32227a6',\n",
       " 'metadata': {},\n",
       " 'outputs': [],\n",
       " 'source': '#| hide\\n%load_ext autoreload\\n%autoreload 2',\n",
       " 'idx_': 0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebddd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets', 'distributed', 'matplotlib', 'polars', 'pyarrow', 'scipy', 'hide']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_flags + ['hide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fa72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "mapper = {\n",
    "    'print_execs': print_execs,\n",
    "    'print_hide': print_hide,\n",
    "    'other_tests': other_tests,\n",
    "    'get_markdown': get_markdown,\n",
    "    'extract_dir': extract_dir,\n",
    "    'no_dir_and_dir': no_dir_and_dir,\n",
    "    'get_all_tests':get_all_tests\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c189eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def print_dir_in_nb(nb_path:str,\n",
    "                    dir:str=None,\n",
    "                    dir_name:str=None,\n",
    "                    ):\n",
    "    if dir_name not in mapper.keys():\n",
    "        raise ValueError(f'Choose processor from the the following: {mapper.keys()}')\n",
    "\n",
    "    if dir_name == 'extract_dir':\n",
    "        processor = NBProcessor(nb_path, partial(extract_dir, dir=dir))\n",
    "        processor.process()\n",
    "        return\n",
    "    elif dir_name == 'no_dir_and_dir':\n",
    "        processor = NBProcessor(nb_path, partial(no_dir_and_dir, dir=dir))\n",
    "        processor.process()\n",
    "        return\n",
    "\n",
    "    processor = NBProcessor(nb_path, mapper[dir_name])\n",
    "    processor.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb108ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "from nbdev import show_doc\n",
      "show_doc(evaluate)\n",
      "from functools import partial\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "from utilsforecast.losses import *\n",
      "from utilsforecast.data import generate_series\n",
      "series = generate_series(10, n_models=2, level=[80, 95])\n",
      "series['unique_id'] = series['unique_id'].astype('int')\n",
      "models = ['model0', 'model1']\n",
      "metrics = [\n",
      "    mae,\n",
      "    mse,\n",
      "    rmse,\n",
      "    mape,\n",
      "    smape,\n",
      "    partial(mase, seasonality=7),\n",
      "    quantile_loss,\n",
      "    mqloss,\n",
      "    coverage,\n",
      "    calibration,\n",
      "    scaled_crps,\n",
      "]\n",
      "evaluation = evaluate(\n",
      "    series,\n",
      "    metrics=metrics,\n",
      "    models=models,\n",
      "    train_df=series,\n",
      "    level=[80, 95],\n",
      ")\n",
      "evaluation\n",
      "summary = evaluation.drop(columns='unique_id').groupby('metric').mean().reset_index()\n",
      "summary\n",
      "import polars.testing\n",
      "series_pl = generate_series(10, n_models=2, level=[80, 95], engine='polars')\n",
      "pl_evaluation = (\n",
      "    evaluate(\n",
      "        series_pl,\n",
      "        metrics=metrics,\n",
      "        train_df=series_pl,\n",
      "        level=[80, 95],\n",
      "    ).drop('unique_id')\n",
      ")\n",
      "pl_summary = ufp.group_by(pl_evaluation, 'metric').mean()\n",
      "pd.testing.assert_frame_equal(\n",
      "    summary.sort_values('metric'),\n",
      "    pl_summary.sort('metric').to_pandas(),\n",
      ")\n",
      "pl.testing.assert_frame_equal(\n",
      "    evaluate(\n",
      "        series_pl, metrics=metrics, train_df=series_pl, level=[80, 95], agg_fn='mean'\n",
      "    ).sort('metric'),\n",
      "    pl_summary.sort('metric'),\n",
      ")\n",
      "from datasetsforecast.evaluation import accuracy as ds_evaluate\n",
      "import datasetsforecast.losses as ds_losses\n",
      "def daily_mase(y, y_hat, y_train):\n",
      "    return ds_losses.mase(y, y_hat, y_train, seasonality=7)\n",
      "\n",
      "level = [80, 95]\n",
      "for agg_fn in [None, 'mean']:\n",
      "    uf_res = evaluate(\n",
      "        series,\n",
      "        metrics=metrics,\n",
      "        models=models,\n",
      "        train_df=series,\n",
      "        level=level,\n",
      "        agg_fn=agg_fn,\n",
      "    )\n",
      "    agg_by = None if agg_fn == 'mean' else ['unique_id']\n",
      "    ds_res = ds_evaluate(\n",
      "        series,\n",
      "        metrics=[\n",
      "            ds_losses.mae,\n",
      "            ds_losses.mse,\n",
      "            ds_losses.rmse,\n",
      "            ds_losses.mape,\n",
      "            daily_mase,\n",
      "            ds_losses.smape,\n",
      "            ds_losses.quantile_loss,        \n",
      "            ds_losses.mqloss,\n",
      "            ds_losses.coverage,        \n",
      "            ds_losses.calibration,\n",
      "            ds_losses.scaled_crps,\n",
      "        ],\n",
      "        level=level,\n",
      "        Y_df=series,\n",
      "        agg_by=agg_by,\n",
      "    )\n",
      "    ds_res['metric'] = ds_res['metric'].str.replace('-', '_')\n",
      "    ds_res['metric'] = ds_res['metric'].str.replace('q_', 'q')\n",
      "    ds_res['metric'] = ds_res['metric'].str.replace('lv_', 'level')\n",
      "    ds_res['metric'] = ds_res['metric'].str.replace('daily_mase', 'mase')\n",
      "    # utils doesn't multiply pct metrics by 100\n",
      "    ds_res.loc[ds_res['metric'].str.startswith('coverage'), ['model0', 'model1']] /= 100\n",
      "    ds_res.loc[ds_res['metric'].eq('mape'), ['model0', 'model1']] /= 100\n",
      "    # we report smape between 0 and 1 instead of 0-200\n",
      "    ds_res.loc[ds_res['metric'].eq('smape'), ['model0', 'model1']] /= 200\n",
      "\n",
      "    ds_res = ds_res[uf_res.columns]\n",
      "    if agg_fn is None:\n",
      "        ds_res = ds_res.sort_values(['unique_id', 'metric'])\n",
      "        uf_res = uf_res.sort_values(['unique_id', 'metric'])\n",
      "    else:\n",
      "        ds_res = ds_res.sort_values('metric')\n",
      "        uf_res = uf_res.sort_values('metric')\n",
      "    \n",
      "    pd.testing.assert_frame_equal(\n",
      "        uf_res.reset_index(drop=True),\n",
      "        ds_res.reset_index(drop=True),\n",
      "    )\n",
      "import sys\n",
      "from itertools import product\n",
      "\n",
      "import dask.dataframe as dd\n",
      "import fugue.api as fa\n",
      "from pyspark.sql import SparkSession\n",
      "if sys.version_info >= (3, 9):\n",
      "    spark = SparkSession.builder.getOrCreate()\n",
      "    spark.sparkContext.setLogLevel('FATAL')\n",
      "    dask_df = dd.from_pandas(series, npartitions=2)\n",
      "    spark_df = spark.createDataFrame(series).repartition(2)\n",
      "    for distributed_df, use_train in product([dask_df, spark_df], [True, False]):\n",
      "        distr_metrics = [rmse, mae]\n",
      "        if use_train:\n",
      "            distr_metrics.append(partial(mase, seasonality=7))\n",
      "            local_train = series\n",
      "            distr_train = distributed_df\n",
      "        else:\n",
      "            local_train = None\n",
      "            distr_train = None\n",
      "        local_res = evaluate(series, metrics=distr_metrics, level=level, train_df=local_train)\n",
      "        distr_res = fa.as_fugue_df(\n",
      "            evaluate(distributed_df, metrics=distr_metrics, level=level, train_df=distr_train)\n",
      "        ).as_pandas()\n",
      "        pd.testing.assert_frame_equal(\n",
      "            local_res.sort_values(['unique_id', 'metric']).reset_index(drop=True),\n",
      "            distr_res.sort_values(['unique_id', 'metric']).reset_index(drop=True),\n",
      "            check_dtype=False,\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "NBProcessor(nb_path, procs=get_all_tests).process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = NBProcessor(nb_path, partial(extract_dir, dir='distributed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import sys\n",
      "from itertools import product\n",
      "\n",
      "import dask.dataframe as dd\n",
      "import fugue.api as fa\n",
      "from pyspark.sql import SparkSession\n",
      "if sys.version_info >= (3, 9):\n",
      "    spark = SparkSession.builder.getOrCreate()\n",
      "    spark.sparkContext.setLogLevel('FATAL')\n",
      "    dask_df = dd.from_pandas(series, npartitions=2)\n",
      "    spark_df = spark.createDataFrame(series).repartition(2)\n",
      "    for distributed_df, use_train in product([dask_df, spark_df], [True, False]):\n",
      "        distr_metrics = [rmse, mae]\n",
      "        if use_train:\n",
      "            distr_metrics.append(partial(mase, seasonality=7))\n",
      "            local_train = series\n",
      "            distr_train = distributed_df\n",
      "        else:\n",
      "            local_train = None\n",
      "            distr_train = None\n",
      "        local_res = evaluate(series, metrics=distr_metrics, level=level, train_df=local_train)\n",
      "        distr_res = fa.as_fugue_df(\n",
      "            evaluate(distributed_df, metrics=distr_metrics, level=level, train_df=distr_train)\n",
      "        ).as_pandas()\n",
      "        pd.testing.assert_frame_equal(\n",
      "            local_res.sort_values(['unique_id', 'metric']).reset_index(drop=True),\n",
      "            distr_res.sort_values(['unique_id', 'metric']).reset_index(drop=True),\n",
      "            check_dtype=False,\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "processor.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61392f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_export(nb_path, '../tests', partial(extract_dir, dir='distributed'), 'foo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c974d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31426130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92247f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs = globtastic('../nbs', file_glob='*.ipynb', recursive=False).map(Path).sorted()\n",
    "tst_flags = 'datasets distributed matplotlib polars pyarrow scipy'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242be5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#12) [Path('../nbs/compat.ipynb'),Path('../nbs/data.ipynb'),Path('../nbs/evaluation.ipynb'),Path('../nbs/feature_engineering.ipynb'),Path('../nbs/grouped_array.ipynb'),Path('../nbs/index.ipynb'),Path('../nbs/losses.ipynb'),Path('../nbs/plotting.ipynb'),Path('../nbs/preprocessing.ipynb'),Path('../nbs/processing.ipynb'),Path('../nbs/read.ipynb'),Path('../nbs/validation.ipynb')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = Path('../tests').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01da20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/Users/deven367/projects/public/utilsforecast/tests')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST_PATH.exists():\n",
    "    TEST_PATH.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522bd94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../nbs/grouped_array.ipynb')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tst in tst_flags:\n",
    "#     for nb in nbs:\n",
    "#         nb_name = nb.stem\n",
    "#         nb_export(nb, lib_path='../tests', procs=partial(extract_dir, dir=tst), name=f'{tst}_{nb_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c848413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tst in tst_flags:\n",
    "#     for nb in nbs:\n",
    "#         nb_name = nb.stem\n",
    "#         code = NBProcessor(nb, partial(extract_dir, dir=tst))\n",
    "#         with open(TEST_PATH / f'{tst}.py', '+a') as f:\n",
    "#             if code.process() is not None:\n",
    "#                 f.write(code.process())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
