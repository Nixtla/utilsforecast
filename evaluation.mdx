# Evaluation

### `evaluate`

```python
evaluate(
    df,
    metrics,
    models=None,
    train_df=None,
    level=None,
    id_col="unique_id",
    time_col="ds",
    target_col="y",
    agg_fn=None,
)
```

Evaluate forecast using different metrics.

**Parameters:**

Name | Type | Description | Default
---- | ---- | ----------- | -------
`df` | <code>pandas, polars, dask or spark DataFrame</code> | Forecasts to evaluate.
Must have `id_col`, `time_col`, `target_col` and models' predictions. | *required*
`metrics` | <code>list of callable</code> | Functions with arguments `df`, `models`,
`id_col`, `target_col` and optionally `train_df`. | *required*
`models` | <code>list of str</code> | Names of the models to evaluate.
If `None` will use every column in the dataframe after removing
id, time and target. Defaults to None. | <code>None</code>
`train_df` | <code>pandas, polars, dask or spark DataFrame</code> | Training set.
Used to evaluate metrics such as `mase`. Defaults to None. | <code>None</code>
`level` | <code>list of int</code> | Prediction interval levels. Used to compute
losses that rely on quantiles. Defaults to None. | <code>None</code>
`id_col` | <code>[str](#str)</code> | Column that identifies each serie.
Defaults to 'unique_id'. | <code>'unique_id'</code>
`time_col` | <code>[str](#str)</code> | Column that identifies each timestep, its values
can be timestamps or integers. Defaults to 'ds'. | <code>'ds'</code>
`target_col` | <code>[str](#str)</code> | Column that contains the target.
Defaults to 'y'. | <code>'y'</code>
`agg_fn` | <code>[str](#str)</code> | Statistic to compute on the scores by id to reduce
them to a single number. Defaults to None. | <code>None</code>

**Returns:**

Type | Description
---- | -----------
<code>[AnyDFType](#utilsforecast.compat.AnyDFType)</code> | pandas, polars, dask or spark DataFrame: Metrics with one row per
(id, metric) combination and one column per model. If `agg_fn` is
not `None`, there is only one row per metric.
