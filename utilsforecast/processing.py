# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/processing.ipynb.

# %% auto 0
__all__ = ['DataFrameProcessing']

# %% ../nbs/processing.ipynb 3
from typing import Union

import numpy as np
import pandas as pd

from .compat import DataFrame, pl_Series
from .grouped_array import GroupedArray

# %% ../nbs/processing.ipynb 4
def _polars_serie_to_double(serie: pl_Series) -> pl_Series:
    import polars as pl

    if serie.dtype == pl.Categorical:
        serie = serie.cast(pl.Utf8)
    return serie.cast(pl.Float64)


def _counts_by_id(df: DataFrame, id_col: str) -> DataFrame:
    id_counts = df[id_col].value_counts()
    if isinstance(id_counts, pd.Series):
        id_counts = id_counts.rename("counts").sort_index().reset_index()
    else:
        id_counts = id_counts.sort(id_col)
    return id_counts


def _value_cols_to_numpy(
    df: DataFrame, id_col: str, time_col: str, target_col: str
) -> np.ndarray:
    value_cols = [
        col for col in df.columns if col not in (id_col, time_col, target_col)
    ]
    # ensure target is the first column
    value_cols = [target_col] + value_cols
    if isinstance(df, pd.DataFrame):
        data = df[value_cols].to_numpy()
    else:
        import polars as pl

        data = df[value_cols].select(pl.all().map(_polars_serie_to_double)).to_numpy()
    return data


def _compute_sort_idxs(df: DataFrame, idx: pd.MultiIndex) -> np.ndarray:
    if isinstance(df, pd.DataFrame):
        sort_idxs = idx.argsort()
    else:
        import polars as pl

        sort_idxs = df.select(pl.arg_sort_by(idx.names).alias("idx"))["idx"].to_numpy()
    return sort_idxs

# %% ../nbs/processing.ipynb 5
class DataFrameProcessing:
    def __init__(
        self,
        freq: Union[str, int],
        id_col: str = "unique_id",
        time_col: str = "ds",
        target_col: str = "y",
    ):
        self.freq = freq
        self.id_col = id_col
        self.time_col = time_col
        self.target_col = target_col

    def process(self, df: DataFrame) -> None:
        times = df[self.time_col].to_numpy()

        # ids
        uids = df[self.id_col].to_numpy()
        id_counts = _counts_by_id(df, self.id_col)
        self.uids = id_counts[self.id_col]

        # indices
        indptr = np.append(
            np.int64(0),
            id_counts["counts"].to_numpy().cumsum().astype(np.int64),
        )
        last_idxs = indptr[1:] - 1

        # data
        data = _value_cols_to_numpy(df, self.id_col, self.time_col, self.target_col)
        # ensure float dtype
        if data.dtype not in (np.float32, np.float64):
            data = data.astype(np.float32)
        # ensure 2dim
        if data.ndim == 1:
            data = data.reshape(-1, 1)

        # check if we need to sort
        idx = pd.MultiIndex.from_arrays(
            [uids, times], names=[self.id_col, self.time_col]
        )
        if not idx.is_monotonic_increasing:
            sort_idxs = _compute_sort_idxs(df, idx)
            data = data[sort_idxs]
            last_idxs = sort_idxs[last_idxs]
        self.ga = GroupedArray(data, indptr)
        self.times = times[last_idxs]
