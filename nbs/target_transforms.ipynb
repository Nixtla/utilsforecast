{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2247f-be0c-4a71-bf79-d260988e8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp target_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639d9d1-0b9f-41b2-b154-3172bf8cbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00a9c6-845d-4840-ad64-68a8d5430836",
   "metadata": {},
   "source": [
    "# Target transforms\n",
    "Transformations that can be applied to the target before fitting and restored after predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae088aa3-7a4e-4c29-98fe-940277d93c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import math\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Please install numba. \"\n",
    "        \"You can find detailed instructions at https://numba.pydata.org/numba-doc/latest/user/installing.html\"\n",
    "    )\n",
    "import numpy as np\n",
    "\n",
    "from utilsforecast.grouped_array import GroupedArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729e6e3-a8ac-497f-a3e1-7526bb643a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _fit(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray,\n",
    "    stats_fn: Callable,\n",
    ") -> np.ndarray:\n",
    "    n_groups = len(indptr) - 1\n",
    "    stats = np.empty((n_groups, 2), dtype=data.dtype)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        stats[i] = stats_fn(data[sl])   \n",
    "    return stats\n",
    "\n",
    "\n",
    "@njit\n",
    "def _transform(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray,\n",
    "    stats: np.ndarray,\n",
    "    tfm_fn: Callable,\n",
    ") -> np.ndarray:\n",
    "    n_groups = len(indptr) - 1\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        offset, scale = stats[i]\n",
    "        out[sl] = tfm_fn(data[sl], offset, scale)\n",
    "    return out\n",
    "\n",
    "\n",
    "@njit\n",
    "def _common_scaler_transform(data: np.ndarray, offset: float, scale: float) -> np.ndarray:\n",
    "    if abs(scale) < np.finfo(data.dtype).eps:\n",
    "        return data\n",
    "    return (data - offset) / scale\n",
    "\n",
    "\n",
    "@njit\n",
    "def _common_scaler_inverse_transform(data: np.ndarray, offset: float, scale: float) -> np.ndarray:\n",
    "    if abs(scale) < np.finfo(data.dtype).eps:\n",
    "        return data\n",
    "    return data * scale + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c487eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseTargetTransform:\n",
    "    \"\"\"Base class used for target transformations.\"\"\"\n",
    "    stats_fn: Callable\n",
    "    \n",
    "    def fit(self, ga: GroupedArray) -> 'BaseTargetTransform':\n",
    "        self.stats_ = _fit(ga.data, ga.indptr, self.stats_fn)\n",
    "        return self\n",
    "\n",
    "    def transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return _transform(ga.data, ga.indptr, self.stats_, _common_scaler_transform)    \n",
    "    \n",
    "    def fit_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return self.fit(ga).transform(ga)\n",
    "    \n",
    "    def inverse_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return _transform(ga.data, ga.indptr, self.stats_, _common_scaler_inverse_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c72031-cdb2-4663-b693-42f7cb54f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _standard_scaler_stats(data: np.ndarray) -> Tuple[float, float]:\n",
    "    return np.nanmean(data), np.nanstd(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67473e24-19f4-4c04-bc4b-13c313cbf52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalStandardScaler(BaseTargetTransform):\n",
    "    \"\"\"Standardizes each serie by subtracting its mean and dividing by its standard deviation.\"\"\"\n",
    "    stats_fn = _standard_scaler_stats    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0daa3f7-c214-4eb8-bd8d-e12095c0be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsforecast.data import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31a606-293f-4591-9e12-0dc9adc0819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_series(10, min_length=50, max_length=100)\n",
    "data = series['y'].values\n",
    "sizes = series.groupby('unique_id', observed=True).size().values\n",
    "indptr = np.append(0, sizes.cumsum())\n",
    "ga = GroupedArray(data, indptr)\n",
    "# introduce some constant series\n",
    "for i, c in zip([0, 3], [10, 0]):\n",
    "    ga.data[ga.indptr[i] : ga.indptr[i + 1]] = c * np.ones(ga[i].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff99e82-09ef-4c39-bca1-892bb134bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transform(tfm, ga):\n",
    "    transformed = tfm.fit_transform(ga)\n",
    "    transformed2 = tfm.transform(ga)\n",
    "    np.testing.assert_allclose(transformed, transformed2)\n",
    "    transformed_ga = GroupedArray(transformed, ga.indptr)\n",
    "    np.testing.assert_allclose(\n",
    "        tfm.inverse_transform(transformed_ga),\n",
    "        ga.data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b8cee7-89e9-4091-9e2f-f8f0da908d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform(LocalStandardScaler(), ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5423a2-e657-48a3-8372-f44e0da31b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _minmax_scaler_stats(data: np.ndarray) -> Tuple[float, float]:\n",
    "    min_ = np.nanmin(data)\n",
    "    max_ = np.nanmax(data)\n",
    "    return min_, max_ - min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8465213-5cd4-494a-bca9-138caf03075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalMinMaxScaler(BaseTargetTransform):\n",
    "    \"\"\"Scales each serie to be in the [0, 1] interval.\"\"\"\n",
    "    stats_fn = _minmax_scaler_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695744ce-5852-4e81-b5c0-43cdf5110d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform(LocalMinMaxScaler(), ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e47f9-4565-4c3d-b7e5-df9c089ed6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _robust_scaler_iqr_stats(data: np.ndarray) -> Tuple[float, float]:\n",
    "    q25, median, q75 = np.nanquantile(data, (0.25, 0.5, 0.75))\n",
    "    return median, q75 - q25\n",
    "\n",
    "\n",
    "@njit\n",
    "def _robust_scaler_mad_stats(data: np.ndarray) -> Tuple[float, float]:\n",
    "    median = np.nanmedian(data)\n",
    "    mad = np.nanmedian(np.abs(data - median))\n",
    "    return median, mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52965c91-e291-4823-a83c-113bed9c5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalRobustScaler(BaseTargetTransform):\n",
    "    \"\"\"Scaler robust to outliers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale : str (default='iqr')\n",
    "        Statistic to use for scaling. Can be either 'iqr' (Inter Quartile Range) or 'mad' (Median Asbolute Deviation)\n",
    "    \"\"\"\n",
    "    def __init__(self, scale: str = 'iqr'):\n",
    "        supported_scales = ('iqr', 'mad')\n",
    "        if scale not in supported_scales:\n",
    "            raise ValueError(f'scale must be one of {supported_scales}')\n",
    "        self.scale = scale\n",
    "\n",
    "    def fit(self, ga: GroupedArray) -> 'LocalRobustScaler':\n",
    "        if self.scale == 'iqr':\n",
    "            stats_fn = _robust_scaler_iqr_stats\n",
    "        else:\n",
    "            stats_fn = _robust_scaler_mad_stats\n",
    "        self.stats_ = _fit(ga.data, ga.indptr, stats_fn)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b6210-bdad-440f-9f99-9617801c125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale in ('iqr', 'mad'):\n",
    "    test_transform(LocalRobustScaler(scale=scale), ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794c323-bbff-4689-8e39-ae64b6f8b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalBoxCox(BaseTargetTransform):\n",
    "    \"\"\"Finds optimum lambda for each serie and applies Box-Cox transformation.\"\"\"\n",
    "    def fit_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        from scipy.stats import boxcox\n",
    "\n",
    "        out = np.full(ga.data.shape, np.nan)\n",
    "        self.lmbdas_ = np.empty(ga.n_groups)\n",
    "        for i in range(ga.n_groups):\n",
    "            sl = slice(ga.indptr[i], ga.indptr[i + 1])\n",
    "            mask = ~np.isnan(ga.data[sl])\n",
    "            try:\n",
    "                transformed, self.lmbdas_[i] = boxcox(ga.data[sl][mask] + 1.0, lmbda=None)\n",
    "            except ValueError:\n",
    "                # this can happen for constant series, fallback to log\n",
    "                self.lmbdas_[i] = 0.0\n",
    "                transformed = np.log1p(ga.data[sl][mask])\n",
    "            if not math.isclose(self.lmbdas_[i], 0.0) and np.isclose(transformed * self.lmbdas_[i], -1).any():\n",
    "                # in this case we can't reliably invert the transformation\n",
    "                # fallback to log\n",
    "                self.lmbdas_[i] = 0.0\n",
    "                transformed = np.log1p(ga.data[sl][mask])\n",
    "            out[sl][mask] = transformed\n",
    "        return out\n",
    "\n",
    "    def transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        from scipy.special import boxcox1p\n",
    "        \n",
    "        sizes = np.diff(ga.indptr)\n",
    "        lmbdas = np.repeat(self.lmbdas_, sizes, axis=0)\n",
    "        return boxcox1p(ga.data, lmbdas)\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        from scipy.special import inv_boxcox1p\n",
    "\n",
    "        sizes = np.diff(ga.indptr)\n",
    "        lmbdas = np.repeat(self.lmbdas_, sizes, axis=0)\n",
    "        return inv_boxcox1p(ga.data, lmbdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3cdb5b-5d6a-46a4-97f9-1c6a1a0e2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform(LocalBoxCox(), ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8ed64-ef96-421d-a4f7-31fd8b72d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GlobalFuncTransformer(BaseTargetTransform):\n",
    "    \"\"\"Uses `func` and `inverse_func` for applying the same transformation to all series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : Callable\n",
    "        Function that transforms the data.\n",
    "    inverse_func : Callable\n",
    "        Function that inverse transforms the data.\n",
    "    \"\"\"\n",
    "    def __init__(self, func: Callable, inverse_func: Callable):\n",
    "        self.func = func\n",
    "        self.inverse_func = inverse_func\n",
    "\n",
    "    def transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return self.func(ga.data)\n",
    "        \n",
    "    def fit_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return self.transform(ga)\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return self.inverse_func(ga.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6da7b-484b-4574-9525-b53675ad5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform(GlobalFuncTransformer(np.log1p, np.expm1), ga)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
