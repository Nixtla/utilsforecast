{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f2247f-be0c-4a71-bf79-d260988e8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp target_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639d9d1-0b9f-41b2-b154-3172bf8cbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00a9c6-845d-4840-ad64-68a8d5430836",
   "metadata": {},
   "source": [
    "# Target transforms\n",
    "Transformations that can be applied to the target before fitting and restored after predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae088aa3-7a4e-4c29-98fe-940277d93c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import abc\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Please install numba. \"\n",
    "        \"You can find detailed instructions at https://numba.pydata.org/numba-doc/latest/user/installing.html\"\n",
    "    )\n",
    "import numpy as np\n",
    "\n",
    "from utilsforecast.grouped_array import GroupedArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c487eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseTargetTransform(abc.ABC):\n",
    "    \"\"\"Base class used for target transformations.\"\"\"\n",
    "    @abc.abstractmethod\n",
    "    def fit_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def inverse_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c98a7-8fc9-4dc4-b697-e9b7056c5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _standard_scaler_transform(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    n_groups = len(indptr) - 1\n",
    "    stats = np.empty((n_groups, 2))\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        mean = np.nanmean(data[sl])\n",
    "        std = np.nanstd(data[sl])\n",
    "        stats[i, :] = mean, std\n",
    "        out[sl] = (data[sl] - mean) / std\n",
    "    return out, stats\n",
    "\n",
    "\n",
    "@njit\n",
    "def _standard_scaler_inverse_transform(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray,\n",
    "    stats: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    n_groups = len(indptr) - 1\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        mean, std = stats[i]\n",
    "        out[sl] = data[sl] * std + mean\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67473e24-19f4-4c04-bc4b-13c313cbf52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalStandardScaler(BaseTargetTransform):\n",
    "    \"\"\"Standardizes each serie by subtracting its mean and dividing by its standard deviation.\"\"\"\n",
    "    def fit_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        transformed, self.stats_ = _standard_scaler_transform(ga.data, ga.indptr)\n",
    "        return transformed\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return _standard_scaler_inverse_transform(ga.data, ga.indptr, self.stats_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0daa3f7-c214-4eb8-bd8d-e12095c0be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsforecast.data import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184ce19-b831-40dd-b241-18ea8ee0cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_series(10, min_length=50, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5c20d-87b4-4784-8f7c-bcff37e2659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = LocalStandardScaler()\n",
    "data = series['y'].values\n",
    "sizes = series.groupby('unique_id', observed=True).size().values\n",
    "indptr = np.append(0, sizes.cumsum())\n",
    "ga = GroupedArray(data, indptr)\n",
    "transformed = sc.fit_transform(ga)\n",
    "transformed_ga = GroupedArray(transformed, ga.indptr)\n",
    "np.testing.assert_allclose(\n",
    "    sc.inverse_transform(transformed_ga),\n",
    "    data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794c323-bbff-4689-8e39-ae64b6f8b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalBoxCox(BaseTargetTransform):\n",
    "    \"\"\"Finds optimum lambda for each serie and applies Box-Cox transformation.\"\"\"\n",
    "    def fit_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        from scipy.stats import boxcox\n",
    "\n",
    "        out = np.full(ga.data.shape, np.nan)\n",
    "        self.lmbdas_ = np.empty(ga.n_groups)\n",
    "        for i in range(ga.n_groups):\n",
    "            sl = slice(ga.indptr[i], ga.indptr[i + 1])\n",
    "            mask = ~np.isnan(ga.data[sl])\n",
    "            transformed, self.lmbdas_[i] = boxcox(ga.data[sl][mask] + 1.0, lmbda=None)\n",
    "            if np.isclose(transformed * self.lmbdas_[i], -1).any():\n",
    "                # in this case we can't reliably invert the transformation\n",
    "                # fallback to log\n",
    "                self.lmbdas_[i] = 0.0\n",
    "                transformed = np.log1p(ga.data[sl][mask])\n",
    "            out[sl][mask] = transformed\n",
    "        return out\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        from scipy.special import inv_boxcox1p\n",
    "\n",
    "        sizes = np.diff(ga.indptr)\n",
    "        lmbdas = np.repeat(self.lmbdas_, sizes, axis=0)\n",
    "        return inv_boxcox1p(ga.data, lmbdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d33a4-6fd9-46ae-b946-5478ef78a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = LocalBoxCox()\n",
    "transformed = bc.fit_transform(ga)\n",
    "transformed_ga = GroupedArray(transformed, ga.indptr)\n",
    "np.testing.assert_allclose(\n",
    "    bc.inverse_transform(transformed_ga),\n",
    "    data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5423a2-e657-48a3-8372-f44e0da31b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _minmax_scaler_transform(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    n_groups = len(indptr) - 1\n",
    "    stats = np.empty((n_groups, 2))\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        min_ = np.nanmin(data[sl])\n",
    "        max_ = np.nanmax(data[sl])\n",
    "        stats[i, :] = min_, max_\n",
    "        out[sl] = (data[sl] - min_) / (max_ - min_)\n",
    "    return out, stats\n",
    "\n",
    "\n",
    "@njit\n",
    "def _minmax_scaler_inverse_transform(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray,\n",
    "    stats: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    n_groups = len(indptr) - 1\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        min_, max_ = stats[i]\n",
    "        out[sl] = data[sl] * (max_ - min_) + min_\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8465213-5cd4-494a-bca9-138caf03075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalMinMaxScaler(BaseTargetTransform):\n",
    "    \"\"\"Scales each serie to be in the [0, 1] interval.\"\"\"\n",
    "    def fit_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        transformed, self.stats_ = _minmax_scaler_transform(ga.data, ga.indptr)\n",
    "        return transformed\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return _minmax_scaler_inverse_transform(ga.data, ga.indptr, self.stats_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259154b-9305-4bf1-8037-0846b2620920",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = LocalMinMaxScaler()\n",
    "transformed = sc.fit_transform(ga)\n",
    "transformed_ga = GroupedArray(transformed, ga.indptr)\n",
    "np.testing.assert_allclose(\n",
    "    sc.inverse_transform(transformed_ga),\n",
    "    data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e47f9-4565-4c3d-b7e5-df9c089ed6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@njit\n",
    "def _robust_scaler_iqr_transform(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    n_groups = len(indptr) - 1\n",
    "    stats = np.empty((n_groups, 3))\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        q25, median, q75 = np.quantile(data[sl], (0.25, 0.5, 0.75))\n",
    "        stats[i] = q25, median, q75\n",
    "        out[sl] = (data[sl] - median) / (q75 - q25)\n",
    "    return out, stats\n",
    "\n",
    "\n",
    "@njit\n",
    "def _robust_scaler_iqr_inverse_transform(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray,\n",
    "    stats: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    n_groups = len(indptr) - 1\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        q25, median, q75 = stats[i]\n",
    "        out[sl] = data[sl] * (q75 - q25) + median\n",
    "    return out\n",
    "\n",
    "\n",
    "@njit\n",
    "def _robust_scaler_mad_transform(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    n_groups = len(indptr) - 1\n",
    "    stats = np.empty((n_groups, 2))\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        median = np.median(data[sl])\n",
    "        shifted = data[sl] - median\n",
    "        mad = np.median(np.abs(shifted))\n",
    "        stats[i] = median, mad\n",
    "        out[sl] = shifted / mad\n",
    "    return out, stats\n",
    "\n",
    "\n",
    "@njit\n",
    "def _robust_scaler_mad_inverse_transform(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray,\n",
    "    stats: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    n_groups = len(indptr) - 1\n",
    "    out = np.empty_like(data)\n",
    "    for i in range(n_groups):\n",
    "        sl = slice(indptr[i], indptr[i + 1])\n",
    "        median, mad = stats[i]\n",
    "        out[sl] = data[sl] * mad + median\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52965c91-e291-4823-a83c-113bed9c5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalRobustScaler(BaseTargetTransform):\n",
    "    \"\"\"Scaler robust to outliers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale : str (default='iqr')\n",
    "        Statistic to use for scaling. Can be either 'iqr' (Inter Quartile Range) or 'mad' (Median Asbolute Deviation)\n",
    "    \"\"\"\n",
    "    def __init__(self, scale: str = 'iqr'):\n",
    "        supported_scales = ('iqr', 'mad')\n",
    "        if scale not in supported_scales:\n",
    "            raise ValueError(f'scale must be one of {supported_scales}')\n",
    "        self.scale = scale\n",
    "\n",
    "    def fit_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        if self.scale == 'iqr':\n",
    "            tfm_fn = _robust_scaler_iqr_transform\n",
    "        else:\n",
    "            tfm_fn = _robust_scaler_mad_transform\n",
    "        transformed, self.stats_ = tfm_fn(ga.data, ga.indptr)\n",
    "        return transformed\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        if self.scale == 'iqr':\n",
    "            inv_tfm_fn = _robust_scaler_iqr_inverse_transform\n",
    "        else:\n",
    "            inv_tfm_fn = _robust_scaler_mad_inverse_transform\n",
    "        return inv_tfm_fn(ga.data, ga.indptr, self.stats_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b6210-bdad-440f-9f99-9617801c125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale in ('iqr', 'mad'):\n",
    "    sc = LocalRobustScaler(scale=scale)\n",
    "    transformed = sc.fit_transform(ga)\n",
    "    transformed_ga = GroupedArray(transformed, ga.indptr)\n",
    "    np.testing.assert_allclose(\n",
    "        sc.inverse_transform(transformed_ga),\n",
    "        data,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8ed64-ef96-421d-a4f7-31fd8b72d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GlobalFuncTransformer(BaseTargetTransform):\n",
    "    \"\"\"Uses `func` and `inverse_func` for applying the same transformation to all series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : Callable\n",
    "        Function that transforms the data.\n",
    "    inverse_func : Callable\n",
    "        Function that inverse transforms the data.\n",
    "    \"\"\"\n",
    "    def __init__(self, func: Callable, inverse_func: Callable):\n",
    "        self.func = func\n",
    "        self.inverse_func = inverse_func\n",
    "        \n",
    "    def fit_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return self.func(ga.data)\n",
    "\n",
    "    def inverse_transform(self, ga: GroupedArray) -> np.ndarray:\n",
    "        return self.inverse_func(ga.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6da7b-484b-4574-9525-b53675ad5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = GlobalFuncTransformer(np.log1p, np.expm1)\n",
    "transformed = sc.fit_transform(ga)\n",
    "transformed_ga = GroupedArray(transformed, ga.indptr)\n",
    "np.testing.assert_allclose(\n",
    "    sc.inverse_transform(transformed_ga),\n",
    "    data,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
