{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Time Series Generation for Benchmarking\n",
    "\n",
    "This tutorial introduces `TimeSeriesSimulator`, a utility for generating\n",
    "synthetic time series data with customizable statistical distributions.\n",
    "This is invaluable for systematically testing how forecasting models\n",
    "perform on data with specific, known characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Synthetic Data?\n",
    "\n",
    "When developing forecasting solutions you often need to answer questions like:\n",
    "\n",
    "- **\"How does my model handle sudden demand spikes?\"** (e.g. from promotions or viral events)\n",
    "- **\"Which model is most robust to heavy-tailed distributions?\"** (e.g. insurance claims, website traffic)\n",
    "- **\"How do different models behave with multiple seasonalities?\"** (e.g. daily + weekly + yearly patterns)\n",
    "\n",
    "Real-world data is messy, expensive to obtain, and you can't control its characteristics. With synthetic data:\n",
    "\n",
    "1. **You know the ground truth** - You designed the data generation process\n",
    "2. **You can isolate specific behaviours** - Test one characteristic at a time\n",
    "3. **You can generate unlimited samples** - No data-scarcity issues\n",
    "4. **Reproducibility** - Same seed = same data, every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilsforecast.synthetic import TimeSeriesSimulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage: Built-in Distributions\n",
    "\n",
    "`TimeSeriesSimulator` ships with seven built-in distributions:\n",
    "`normal`, `poisson`, `exponential`, `gamma`, `uniform`, `binomial`, `lognormal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = TimeSeriesSimulator(\n",
    "    length=100,\n",
    "    distribution=\"normal\",\n",
    "    dist_params={\"loc\": 100, \"scale\": 15},\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate(n_series=3)\n",
    "print(f\"Generated {df['unique_id'].nunique()} series with {len(df)} total rows\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "for uid in df[\"unique_id\"].unique():\n",
    "    subset = df[df[\"unique_id\"] == uid]\n",
    "    ax.plot(subset[\"ds\"], subset[\"y\"], label=f\"Series {uid}\", alpha=0.7)\n",
    "ax.set_title(\"Normal Distribution (loc=100, scale=15)\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Trend and Seasonality\n",
    "\n",
    "Real time series often have trend and seasonal components. `TimeSeriesSimulator` supports:\n",
    "\n",
    "**Trends:** `linear`, `quadratic`, `exponential`, or any custom callable.\n",
    "\n",
    "**Seasonality:** single or multiple periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = TimeSeriesSimulator(\n",
    "    length=180,\n",
    "    distribution=\"gamma\",\n",
    "    dist_params={\"shape\": 5, \"scale\": 10},\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.2, \"intercept\": 0},\n",
    "    seasonality=7,\n",
    "    seasonality_strength=15.0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(df[\"ds\"], df[\"y\"])\n",
    "ax.set_title(\"Gamma + Linear Trend + Weekly Seasonality\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = TimeSeriesSimulator(\n",
    "    length=365,\n",
    "    distribution=\"normal\",\n",
    "    dist_params={\"loc\": 100, \"scale\": 5},\n",
    "    seasonality=[7, 30],\n",
    "    seasonality_strength=[10.0, 20.0],\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(df[\"ds\"], df[\"y\"])\n",
    "ax.set_title(\"Multiple Seasonalities: Weekly (amplitude=10) + Monthly (amplitude=20)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Key Feature: Custom Distributions\n",
    "\n",
    "**This is why `TimeSeriesSimulator` exists.**\n",
    "\n",
    "Built-in distributions are useful, but real-world data often has complex patterns that don't fit standard distributions. The `distribution` parameter accepts any callable with signature:\n",
    "\n",
    "```python\n",
    "def my_distribution(size: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    # Generate `size` values using `rng` for reproducibility\n",
    "    return values\n",
    "```\n",
    "\n",
    "This gives you **complete control** over the data-generation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Demand with Promotional Spikes\n",
    "\n",
    "In retail forecasting, demand usually follows a gamma-like distribution, but promotional events cause sudden spikes. How do different models handle this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_with_spikes(size, rng):\n",
    "    \"\"\"Simulate retail demand with random promotional spikes.\"\"\"\n",
    "    base_demand = rng.gamma(shape=5, scale=10, size=size)\n",
    "    spike_mask = rng.random(size) < 0.05  # 5% of days have spikes\n",
    "    spike_multiplier = rng.uniform(2.5, 5.0, size=size)\n",
    "    demand = base_demand.copy()\n",
    "    demand[spike_mask] *= spike_multiplier[spike_mask]\n",
    "    return demand\n",
    "\n",
    "\n",
    "sim = TimeSeriesSimulator(\n",
    "    length=365,\n",
    "    distribution=demand_with_spikes,\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.05},\n",
    "    seasonality=7,\n",
    "    seasonality_strength=10.0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate(n_series=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(df[\"ds\"], df[\"y\"], alpha=0.8)\n",
    "ax.axhline(\n",
    "    df[\"y\"].mean(), color=\"red\", linestyle=\"--\",\n",
    "    label=f\"Mean: {df['y'].mean():.1f}\",\n",
    ")\n",
    "ax.set_title(\"Retail Demand with Promotional Spikes\")\n",
    "ax.set_ylabel(\"Demand\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Normal range: {df['y'].quantile(0.05):.1f} - {df['y'].quantile(0.95):.1f}\")\n",
    "print(f\"Max (spike):  {df['y'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Bimodal Distribution (Two Customer Segments)\n",
    "\n",
    "Imagine two customer segments with different spending patterns - some spend ~$20, others spend ~$80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bimodal_spending(size, rng):\n",
    "    \"\"\"Two customer segments with different spending patterns.\"\"\"\n",
    "    segment = rng.random(size) < 0.6  # 60% low spenders\n",
    "    values = np.zeros(size)\n",
    "    values[segment] = rng.normal(20, 5, size=segment.sum())\n",
    "    values[~segment] = rng.normal(80, 10, size=(~segment).sum())\n",
    "    return np.maximum(values, 0)\n",
    "\n",
    "\n",
    "sim = TimeSeriesSimulator(length=200, distribution=bimodal_spending, seed=42)\n",
    "df = sim.simulate()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(df[\"ds\"], df[\"y\"], alpha=0.7)\n",
    "axes[0].set_title(\"Bimodal Spending Over Time\")\n",
    "axes[0].set_ylabel(\"Spending ($)\")\n",
    "axes[1].hist(df[\"y\"], bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "axes[1].set_title(\"Spending Distribution (Two Segments)\")\n",
    "axes[1].set_xlabel(\"Spending ($)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Regime Changes (Market Conditions)\n",
    "\n",
    "Financial or economic data often exhibits regime changes - periods of low volatility followed by high volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regime_switching(size, rng):\n",
    "    \"\"\"Alternating regimes of low and high volatility.\"\"\"\n",
    "    values = np.zeros(size)\n",
    "    regime_length = 50\n",
    "    for i in range(0, size, regime_length):\n",
    "        end = min(i + regime_length, size)\n",
    "        segment_size = end - i\n",
    "        if (i // regime_length) % 2 == 0:\n",
    "            values[i:end] = rng.normal(100, 5, size=segment_size)\n",
    "        else:\n",
    "            values[i:end] = rng.normal(100, 25, size=segment_size)\n",
    "    return values\n",
    "\n",
    "\n",
    "sim = TimeSeriesSimulator(length=300, distribution=regime_switching, seed=42)\n",
    "df = sim.simulate()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.plot(df[\"ds\"], df[\"y\"], alpha=0.8)\n",
    "for i in range(1, 6, 2):\n",
    "    start_idx = i * 50\n",
    "    end_idx = min((i + 1) * 50, 300)\n",
    "    if start_idx < 300:\n",
    "        ax.axvspan(\n",
    "            df[\"ds\"].iloc[start_idx],\n",
    "            df[\"ds\"].iloc[min(end_idx - 1, 299)],\n",
    "            alpha=0.2, color=\"red\",\n",
    "            label=\"High volatility\" if i == 1 else \"\",\n",
    "        )\n",
    "ax.set_title(\"Regime Switching: Alternating Calm and Volatile Periods\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Benchmarking with Cross-Validation\n",
    "\n",
    "Now let's see the real power: **comparing how different models perform on our custom distributions**.\n",
    "\n",
    "We'll use StatsForecast's `cross_validation` method together with `utilsforecast.evaluation.evaluate` to benchmark models on spike-prone demand data.\n",
    "\n",
    "> **Note:** The cells below require `statsforecast` to be installed. Install it with `pip install statsforecast` if you want to run them locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoETS, MSTL, SeasonalNaive\n",
    "\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mae, rmse, smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Generate Synthetic Data with Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = TimeSeriesSimulator(\n",
    "    length=200,\n",
    "    distribution=demand_with_spikes,\n",
    "    trend=\"linear\",\n",
    "    trend_params={\"slope\": 0.1},\n",
    "    seasonality=7,\n",
    "    seasonality_strength=10.0,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "df = sim.simulate(n_series=10)\n",
    "\n",
    "print(f\"Generated {df['unique_id'].nunique()} series\")\n",
    "print(f\"Total observations: {len(df)}\")\n",
    "print(f\"Date range: {df['ds'].min().date()} to {df['ds'].max().date()}\")\n",
    "\n",
    "sample = df[df[\"unique_id\"] == 0]\n",
    "fig, ax = plt.subplots(figsize=(12, 3))\n",
    "ax.plot(sample[\"ds\"], sample[\"y\"])\n",
    "ax.set_title(\"Sample Series: Demand with Promotional Spikes\")\n",
    "ax.set_ylabel(\"Demand\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Cross-Validate Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = StatsForecast(\n",
    "    models=[\n",
    "        SeasonalNaive(season_length=7),\n",
    "        AutoETS(season_length=7),\n",
    "        MSTL(season_length=7),\n",
    "    ],\n",
    "    freq=\"D\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "cv_results = sf.cross_validation(df=df, h=14, n_windows=3, step_size=14)\n",
    "print(f\"Cross-validation results shape: {cv_results.shape}\")\n",
    "cv_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = [\n",
    "    c for c in cv_results.columns\n",
    "    if c not in [\"unique_id\", \"ds\", \"cutoff\", \"y\"]\n",
    "]\n",
    "print(f\"Models evaluated: {model_cols}\")\n",
    "\n",
    "evaluation = evaluate(\n",
    "    cv_results,\n",
    "    metrics=[mae, rmse, smape],\n",
    "    models=model_cols,\n",
    ")\n",
    "\n",
    "avg_metrics = evaluation.groupby(\"metric\")[model_cols].mean()\n",
    "print(\"\\n=== Average Performance Across All Series ===\")\n",
    "avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "colors = [\"#2ecc71\", \"#3498db\", \"#9b59b6\"]\n",
    "\n",
    "for idx, metric_name in enumerate([\"mae\", \"rmse\"]):\n",
    "    if metric_name in avg_metrics.index:\n",
    "        values = avg_metrics.loc[metric_name]\n",
    "        bars = axes[idx].bar(values.index, values.values, color=colors)\n",
    "        axes[idx].set_title(f\"{metric_name.upper()} by Model\")\n",
    "        axes[idx].set_ylabel(metric_name.upper())\n",
    "        for bar, val in zip(bars, values.values):\n",
    "            axes[idx].text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                bar.get_height() + 0.5,\n",
    "                f\"{val:.1f}\",\n",
    "                ha=\"center\", va=\"bottom\", fontsize=10,\n",
    "            )\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Model Comparison on Spike-Prone Demand Data\",\n",
    "    fontsize=12, fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Compare Across Distribution Scenarios\n",
    "\n",
    "The real insight comes from running the **same benchmark** on different synthetic distributions and observing how model rankings change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_on_distribution(dist_func, seed=42):\n",
    "    \"\"\"Run a benchmark and return average MAE per model.\"\"\"\n",
    "    sim = TimeSeriesSimulator(\n",
    "        length=200,\n",
    "        distribution=dist_func,\n",
    "        trend=\"linear\",\n",
    "        trend_params={\"slope\": 0.1},\n",
    "        seasonality=7,\n",
    "        seasonality_strength=10.0,\n",
    "        seed=seed,\n",
    "    )\n",
    "    bench_df = sim.simulate(n_series=5)\n",
    "\n",
    "    sf = StatsForecast(\n",
    "        models=[\n",
    "            SeasonalNaive(season_length=7),\n",
    "            AutoETS(season_length=7),\n",
    "            MSTL(season_length=7),\n",
    "        ],\n",
    "        freq=\"D\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    cv = sf.cross_validation(df=bench_df, h=14, n_windows=2, step_size=14)\n",
    "    m_cols = [\n",
    "        c for c in cv.columns if c not in [\"unique_id\", \"ds\", \"cutoff\", \"y\"]\n",
    "    ]\n",
    "    eval_df = evaluate(cv, metrics=[mae], models=m_cols)\n",
    "    return eval_df[m_cols].mean()\n",
    "\n",
    "\n",
    "def smooth_gamma(size, rng):\n",
    "    \"\"\"Smooth gamma - no spikes.\"\"\"\n",
    "    return rng.gamma(shape=5, scale=10, size=size)\n",
    "\n",
    "\n",
    "def high_spike_demand(size, rng):\n",
    "    \"\"\"Higher spike probability (15%).\"\"\"\n",
    "    base = rng.gamma(shape=5, scale=10, size=size)\n",
    "    mask = rng.random(size) < 0.15\n",
    "    base[mask] *= rng.uniform(3.0, 6.0, size=mask.sum())\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running benchmarks on different distributions ...\\n\")\n",
    "\n",
    "results = {}\n",
    "for dist_func, name in [\n",
    "    (smooth_gamma, \"Smooth (No Spikes)\"),\n",
    "    (demand_with_spikes, \"5% Spikes\"),\n",
    "    (high_spike_demand, \"15% Spikes\"),\n",
    "]:\n",
    "    print(f\"  Benchmarking: {name}\")\n",
    "    results[name] = benchmark_on_distribution(dist_func)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame(results).T\n",
    "comparison.columns = [c.replace(\"-mae\", \"\") for c in comparison.columns]\n",
    "print(\"=== MAE by Distribution Type ===\")\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(len(comparison.columns))\n",
    "width = 0.25\n",
    "\n",
    "for i, (dist_name, row) in enumerate(comparison.iterrows()):\n",
    "    ax.bar(x + i * width, row.values, width, label=dist_name, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"MAE\")\n",
    "ax.set_title(\"How Spike Frequency Affects Model Performance\")\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(comparison.columns)\n",
    "ax.legend(title=\"Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights\n",
    "\n",
    "By using `TimeSeriesSimulator` with different custom distributions we can systematically answer questions like:\n",
    "\n",
    "1. **Which model is most robust to spikes?** Compare performance across spike frequencies.\n",
    "2. **Does adding complexity help?** Compare simple (SeasonalNaive) vs complex (AutoARIMA) models.\n",
    "3. **What is the cost of outliers?** Compare smooth vs spike-prone distributions.\n",
    "\n",
    "This **controlled experimentation** is impossible with real-world data alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "`TimeSeriesSimulator` enables systematic model evaluation by generating synthetic data with:\n",
    "\n",
    "| Feature | Options |\n",
    "|---|---|\n",
    "| **Distribution** | 7 built-in + any custom callable |\n",
    "| **Trend** | linear, quadratic, exponential, custom |\n",
    "| **Seasonality** | Single or multiple periods |\n",
    "| **Noise** | Additional Gaussian noise |\n",
    "| **Output** | Pandas or Polars DataFrame |\n",
    "\n",
    "**Workflow:**\n",
    "\n",
    "1. Define a custom distribution encoding domain knowledge (spikes, regimes, etc.).\n",
    "2. Generate synthetic data with `TimeSeriesSimulator`.\n",
    "3. Cross-validate multiple models with `StatsForecast` (or any Nixtla forecasting library).\n",
    "4. Evaluate with `utilsforecast.evaluation.evaluate()`.\n",
    "5. Compare results across distribution scenarios.\n",
    "\n",
    "The custom callable interface lets you model domain-specific behaviours that don't fit standard distributions, making your model benchmarks more realistic and actionable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
