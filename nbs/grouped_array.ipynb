{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb721841-9405-428c-96af-f05bc40d1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp grouped_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e16ea-8b96-4d42-8b82-40ea12507b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utilsforecast.compat import DataFrame\n",
    "from utilsforecast.processing import counts_by_id, value_cols_to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5861c1-02c4-4298-b09e-c29bf2c95fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _append_one(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray,\n",
    "    new: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Append each value of new to each group in data formed by indptr.\"\"\"\n",
    "    n_groups = len(indptr) - 1\n",
    "    n_rows = data.shape[0] + new.shape[0]\n",
    "    if data.ndim == 2:\n",
    "        new_data = np.empty_like(data, shape=(n_rows, data.shape[1]))\n",
    "    else:\n",
    "        new_data = np.empty_like(data, shape=n_rows)\n",
    "    new_indptr = indptr.copy()\n",
    "    new_indptr[1:] += np.arange(1, n_groups + 1)\n",
    "    for i in range(n_groups):\n",
    "        prev_slice = slice(indptr[i], indptr[i + 1])\n",
    "        new_slice = slice(new_indptr[i], new_indptr[i + 1] - 1)\n",
    "        new_data[new_slice] = data[prev_slice]\n",
    "        new_data[new_indptr[i + 1] - 1] = new[i]\n",
    "    return new_data, new_indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11faa9b7-185e-44e7-b7e2-47054efd5491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test _append_one\n",
    "data = np.arange(5)\n",
    "indptr = np.array([0, 2, 5])\n",
    "new = np.array([7, 8])\n",
    "new_data, new_indptr = _append_one(data, indptr, new)\n",
    "np.testing.assert_equal(\n",
    "    new_data,\n",
    "    np.array([0, 1, 7, 2, 3, 4, 8])\n",
    ")\n",
    "np.testing.assert_equal(\n",
    "    new_indptr,\n",
    "    np.array([0, 3, 7]),\n",
    ")\n",
    "\n",
    "# 2d\n",
    "data = np.arange(5).reshape(-1, 1)\n",
    "new_data, new_indptr = _append_one(data, indptr, new)\n",
    "np.testing.assert_equal(\n",
    "    new_data,\n",
    "    np.array([0, 1, 7, 2, 3, 4, 8]).reshape(-1, 1)\n",
    ")\n",
    "np.testing.assert_equal(\n",
    "    new_indptr,\n",
    "    np.array([0, 3, 7]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28549183-4c91-4ffb-9957-7147225264c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _append_several(\n",
    "    data: np.ndarray,\n",
    "    indptr: np.ndarray,\n",
    "    new_sizes: np.ndarray,\n",
    "    new_values: np.ndarray,\n",
    "    new_groups: np.ndarray,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    n_rows = data.shape[0] + new_values.shape[0]\n",
    "    if data.ndim == 2:\n",
    "        new_data = np.empty_like(data, shape=(n_rows, data.shape[1]))\n",
    "    else:\n",
    "        new_data = np.empty_like(data, shape=n_rows)\n",
    "    new_indptr = np.empty_like(indptr, shape=new_sizes.size + 1)\n",
    "    new_indptr[0] = 0\n",
    "    old_indptr_idx = 0\n",
    "    new_vals_idx = 0\n",
    "    for i, is_new in enumerate(new_groups):\n",
    "        new_size = new_sizes[i]\n",
    "        if is_new:\n",
    "            old_size = 0\n",
    "        else:\n",
    "            prev_slice = slice(indptr[old_indptr_idx], indptr[old_indptr_idx + 1])\n",
    "            old_indptr_idx += 1\n",
    "            old_size = prev_slice.stop - prev_slice.start\n",
    "            new_size += old_size\n",
    "            new_data[new_indptr[i] : new_indptr[i] + old_size] = data[prev_slice]\n",
    "        new_indptr[i + 1] = new_indptr[i] + new_size\n",
    "        new_data[new_indptr[i] + old_size : new_indptr[i + 1]] = new_values[\n",
    "            new_vals_idx : new_vals_idx + new_sizes[i]\n",
    "        ]\n",
    "        new_vals_idx += new_sizes[i]\n",
    "    return new_data, new_indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e349b0a-926b-400f-b37e-0f527696984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test append several\n",
    "data = np.arange(5)\n",
    "indptr = np.array([0, 2, 5])\n",
    "new_sizes = np.array([0, 2, 1])\n",
    "new_values = np.array([6, 7, 5])\n",
    "new_groups = np.array([False, True, False])\n",
    "new_data, new_indptr = _append_several(data, indptr, new_sizes, new_values, new_groups)\n",
    "np.testing.assert_equal(\n",
    "    new_data,\n",
    "    np.array([0, 1, 6, 7, 2, 3, 4, 5])\n",
    ")\n",
    "np.testing.assert_equal(\n",
    "    new_indptr,\n",
    "    np.array([0, 2, 4, 8]),\n",
    ")\n",
    "\n",
    "# 2d\n",
    "data = np.arange(5).reshape(-1, 1)\n",
    "indptr = np.array([0, 2, 5])\n",
    "new_sizes = np.array([0, 2, 1])\n",
    "new_values = np.array([6, 7, 5]).reshape(-1, 1)\n",
    "new_groups = np.array([False, True, False])\n",
    "new_data, new_indptr = _append_several(data, indptr, new_sizes, new_values, new_groups)\n",
    "np.testing.assert_equal(\n",
    "    new_data,\n",
    "    np.array([0, 1, 6, 7, 2, 3, 4, 5]).reshape(-1, 1)\n",
    ")\n",
    "np.testing.assert_equal(\n",
    "    new_indptr,\n",
    "    np.array([0, 2, 4, 8]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681a3b8-1cde-47b0-bc46-954b999fb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GroupedArray:\n",
    "    def __init__(self, data: np.ndarray, indptr: np.ndarray):\n",
    "        self.data = data\n",
    "        self.indptr = indptr\n",
    "        self.n_groups = len(indptr) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_groups\n",
    "\n",
    "    def __getitem__(self, idx: int) -> np.ndarray:\n",
    "        if idx < 0:\n",
    "            idx = self.n_groups + idx\n",
    "        return self.data[self.indptr[idx] : self.indptr[idx + 1]]\n",
    "\n",
    "    @classmethod\n",
    "    def from_sorted_df(\n",
    "        cls, df: DataFrame, id_col: str, time_col: str, target_col: str\n",
    "    ) -> 'GroupedArray':\n",
    "        id_counts = counts_by_id(df, id_col)\n",
    "        sizes = id_counts['counts'].to_numpy()\n",
    "        indptr = np.append(0, sizes.cumsum())\n",
    "        data = value_cols_to_numpy(df, id_col, time_col, target_col)\n",
    "        if data.dtype not in (np.float32, np.float64):\n",
    "            data = data.astype(np.float32)\n",
    "        return cls(data, indptr)\n",
    "\n",
    "    def _take_from_ranges(self, ranges: Sequence) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        items = [self.data[r] for r in ranges]\n",
    "        sizes = np.array([item.shape[0] for item in items])\n",
    "        if self.data.ndim == 2:\n",
    "            data = np.vstack(items)\n",
    "        else:\n",
    "            data = np.hstack(items)\n",
    "        indptr = np.append(0, sizes.cumsum())\n",
    "        return data, indptr\n",
    "\n",
    "    def take(self, idxs: Sequence[int]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Subset specific groups by their indices.\"\"\"\n",
    "        ranges = [range(self.indptr[i], self.indptr[i + 1]) for i in idxs]\n",
    "        return self._take_from_ranges(ranges)\n",
    "\n",
    "    def take_from_groups(self, idx: Union[int, slice]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Select a subset from each group.\"\"\"\n",
    "        if isinstance(idx, int):\n",
    "            # this preserves the 2d structure of data when indexing with the range\n",
    "            idx = slice(idx, idx + 1)\n",
    "        ranges = [\n",
    "            range(self.indptr[i], self.indptr[i + 1])[idx]\n",
    "            for i in range(self.n_groups)\n",
    "        ]\n",
    "        return self._take_from_ranges(ranges)\n",
    "\n",
    "    def append(self, new: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Appends each element of `new` to each existing group. Returns a copy.\"\"\"\n",
    "        if new.shape[0] != self.n_groups:\n",
    "            raise ValueError(f\"new must have {self.n_groups} rows.\")\n",
    "        return _append_one(self.data, self.indptr, new)\n",
    "\n",
    "    def append_several(\n",
    "        self, new_sizes: np.ndarray, new_values: np.ndarray, new_groups: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return _append_several(\n",
    "            self.data, self.indptr, new_sizes, new_values, new_groups\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(n_rows={self.data.shape[0]:,}, n_groups={self.n_groups:,})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bd1550-de59-4008-9441-753366477970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq, test_fail\n",
    "\n",
    "from utilsforecast.data import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ab99c-aaec-455a-98c7-318a3dad3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `GroupedArray` is used internally for storing the series values and performing transformations.\n",
    "data = np.arange(20, dtype=np.float32).reshape(-1, 2)\n",
    "indptr = np.array([0, 2, 10])  # group 1: [0, 1], group 2: [2..9]\n",
    "ga = GroupedArray(data, indptr)\n",
    "test_eq(len(ga), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571f0b0-ccea-4bbc-9892-2864c6895a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the groups\n",
    "ga_iter = iter(ga)\n",
    "np.testing.assert_equal(next(ga_iter), np.arange(4).reshape(-1, 2))\n",
    "np.testing.assert_equal(next(ga_iter), np.arange(4, 20).reshape(-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91761fea-19d7-4707-b4db-e74ba152010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the last two observations from each group\n",
    "last2_data, last2_indptr = ga.take_from_groups(slice(-2, None))\n",
    "np.testing.assert_equal(\n",
    "    last2_data,\n",
    "    np.vstack([\n",
    "        np.arange(4).reshape(-1, 2),\n",
    "        np.arange(16, 20).reshape(-1, 2),\n",
    "    ]),\n",
    ")\n",
    "np.testing.assert_equal(last2_indptr, np.array([0, 2, 4]))\n",
    "\n",
    "# 1d\n",
    "ga1d = GroupedArray(np.arange(10), indptr)\n",
    "last2_data1d, last2_indptr1d = ga1d.take_from_groups(slice(-2, None))\n",
    "np.testing.assert_equal(\n",
    "    last2_data1d,\n",
    "    np.array([0, 1, 8, 9])\n",
    ")\n",
    "np.testing.assert_equal(last2_indptr1d, np.array([0, 2, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d635e1-9194-4547-8be9-2452b1f4f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the second observation from each group\n",
    "second_data, second_indptr = ga.take_from_groups(1)\n",
    "np.testing.assert_equal(second_data, np.array([[2, 3], [6, 7]]))\n",
    "np.testing.assert_equal(second_indptr, np.array([0, 1, 2]))\n",
    "\n",
    "# 1d\n",
    "second_data1d, second_indptr1d = ga1d.take_from_groups(1)\n",
    "np.testing.assert_equal(second_data1d, np.array([1, 3]))\n",
    "np.testing.assert_equal(second_indptr1d, np.array([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987419a-f933-4706-a671-01ed31892b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the last four observations from every group. Note that since group 1 only has two elements, only these are returned.\n",
    "last4_data, last4_indptr = ga.take_from_groups(slice(-4, None))\n",
    "np.testing.assert_equal(\n",
    "    last4_data,\n",
    "    np.vstack([\n",
    "        np.arange(4).reshape(-1, 2),\n",
    "        np.arange(12, 20).reshape(-1, 2),\n",
    "    ]),\n",
    ")\n",
    "np.testing.assert_equal(last4_indptr, np.array([0, 2, 6]))\n",
    "\n",
    "# 1d\n",
    "last4_data1d, last4_indptr1d = ga1d.take_from_groups(slice(-4, None))\n",
    "np.testing.assert_equal(\n",
    "    last4_data1d,\n",
    "    np.array([0, 1, 6, 7, 8, 9])\n",
    ")\n",
    "np.testing.assert_equal(last4_indptr1d, np.array([0, 2, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad7d17-81b0-4417-997a-ac9e6920ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a specific subset of groups\n",
    "indptr = np.array([0, 2, 4, 7, 10])\n",
    "ga2 = GroupedArray(data, indptr)\n",
    "subset = GroupedArray(*ga2.take([0, 2]))\n",
    "np.testing.assert_allclose(subset[0].data, ga2[0].data)\n",
    "np.testing.assert_allclose(subset[1].data, ga2[2].data)\n",
    "\n",
    "# 1d\n",
    "ga2_1d = GroupedArray(np.arange(10), indptr)\n",
    "subset1d = GroupedArray(*ga2_1d.take([0, 2]))\n",
    "np.testing.assert_allclose(subset1d[0].data, ga2_1d[0].data)\n",
    "np.testing.assert_allclose(subset1d[1].data, ga2_1d[2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19d1f9-3567-4523-8ac3-cd2e05d3a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to append new values that don't match the number of groups\n",
    "test_fail(lambda: ga.append(np.array([1., 2., 3.])), contains='new must have 2 rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06325e0-8265-4a61-b936-7fc29d6396be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "# build from df\n",
    "series_pd = generate_series(10, static_as_categorical=False, engine='pandas')\n",
    "ga_pd = GroupedArray.from_sorted_df(series_pd, 'unique_id', 'ds', 'y')\n",
    "series_pl = generate_series(10, static_as_categorical=False, engine='polars')\n",
    "ga_pl = GroupedArray.from_sorted_df(series_pl, 'unique_id', 'ds', 'y')\n",
    "np.testing.assert_allclose(ga_pd.data, ga_pl.data)\n",
    "np.testing.assert_equal(ga_pd.indptr, ga_pl.indptr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
