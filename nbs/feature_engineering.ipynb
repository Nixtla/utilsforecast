{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4a137f-33c8-4426-92fa-b74e0d1fb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9fee8b-a4cb-4076-91fd-d748ef060404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp feature_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c002456b-0f6f-45e8-b66f-9890606d4a70",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "> Create exogenous regressors for your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10490557-ac6e-4b3f-8f96-6c212a4c10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from functools import partial\n",
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utilsforecast.processing as ufp\n",
    "from utilsforecast.compat import DFType, DataFrame, pl, pl_DataFrame, pl_Expr\n",
    "from utilsforecast.validation import validate_format, validate_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70c32b-cf3c-4988-8fde-a54b8252b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "_Features = Tuple[List[str], np.ndarray, np.ndarray]\n",
    "\n",
    "def _add_features(\n",
    "    df: DFType,\n",
    "    freq: Union[str, int],\n",
    "    h: int,\n",
    "    id_col: str,\n",
    "    time_col: str,\n",
    "    f: Callable[[np.ndarray, int], _Features],\n",
    ") -> Tuple[DFType, DFType]:\n",
    "    # validations\n",
    "    if not isinstance(h, int) or h < 0:\n",
    "        raise ValueError('`h` must be a non-negative integer')\n",
    "    validate_format(df, id_col, time_col, None)\n",
    "    validate_freq(df[time_col], freq)\n",
    "\n",
    "    # decompose series\n",
    "    id_counts = ufp.counts_by_id(df, id_col)\n",
    "    uids = id_counts[id_col]\n",
    "    sizes = id_counts['counts'].to_numpy()\n",
    "\n",
    "    # compute values\n",
    "    cols, vals, future_vals = f(sizes=sizes, h=h)  # type: ignore\n",
    "\n",
    "    # assign back to df\n",
    "    sort_idxs = ufp.maybe_compute_sort_indices(df, id_col, time_col)\n",
    "    times = df[time_col]\n",
    "    if sort_idxs is not None:\n",
    "        restore_idxs = np.empty_like(sort_idxs)\n",
    "        restore_idxs[sort_idxs] = np.arange(sort_idxs.size)\n",
    "        vals = vals[restore_idxs]\n",
    "        times = ufp.take_rows(times, sort_idxs)\n",
    "    last_times = ufp.take_rows(times, sizes.cumsum() - 1)\n",
    "    df = ufp.copy_if_pandas(df, deep=False)\n",
    "    transformed = ufp.assign_columns(df, cols, vals)\n",
    "\n",
    "    if h == 0:\n",
    "        return transformed, type(df)({})\n",
    "\n",
    "    # future vals\n",
    "    future_df = ufp.make_future_dataframe(\n",
    "        uids=uids,\n",
    "        last_times=last_times,\n",
    "        freq=freq,\n",
    "        h=h,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "    )\n",
    "    future_df = ufp.assign_columns(future_df, cols, future_vals)\n",
    "    return transformed, future_df\n",
    "\n",
    "def _assign_slices(\n",
    "    sizes: np.ndarray,\n",
    "    feats: np.ndarray,\n",
    "    h: int,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    max_samples, n_feats = feats.shape\n",
    "    vals = np.empty((sizes.sum(), n_feats), dtype=np.float32)\n",
    "    future_vals = np.empty((h * sizes.size, n_feats))\n",
    "    start = 0\n",
    "    for i, size in enumerate(sizes):\n",
    "        vals[start : start + size, :] = feats[max_samples - size - h : max_samples - h]\n",
    "        future_vals[i * h: (i + 1) * h] = feats[max_samples - h :]\n",
    "        start += size\n",
    "    return vals, future_vals\n",
    "\n",
    "def _fourier(\n",
    "    sizes: np.ndarray,\n",
    "    h: int,\n",
    "    season_length: int,\n",
    "    k: int,\n",
    ") -> _Features:\n",
    "    # taken from: https://github.com/tblume1992/TSUtilities/blob/main/TSUtilities/TSFeatures/fourier_seasonality.py\n",
    "    x = 2 * np.pi * np.arange(1, k + 1) / season_length\n",
    "    x = x.astype(np.float32)\n",
    "    t = np.arange(1, sizes.max() + 1 + h, dtype=np.float32)\n",
    "    x = x * t[:, None]\n",
    "    terms = np.hstack([np.sin(x), np.cos(x)])\n",
    "    cols = [f'{op}{i+1}_{season_length}' for op in ('sin', 'cos') for i in range(k)]\n",
    "    vals, future_vals = _assign_slices(sizes=sizes, feats=terms, h=h)\n",
    "    return cols, vals, future_vals\n",
    "\n",
    "def _trend(sizes: np.ndarray, h: int) -> _Features:\n",
    "    t = np.arange(1, sizes.max() + 1 + h, dtype=np.float32).reshape(-1, 1)\n",
    "    cols = ['trend']\n",
    "    vals, future_vals = _assign_slices(sizes=sizes, feats=t, h=h)\n",
    "    return cols, vals, future_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45d633-507b-4985-a847-9dc1a748f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fourier(\n",
    "    df: DFType,\n",
    "    freq: Union[str, int],\n",
    "    season_length: int,\n",
    "    k: int,\n",
    "    h: int = 0,\n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    ") -> Tuple[DFType, DFType]:\n",
    "    \"\"\"Compute fourier seasonal terms for training and forecasting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Dataframe with ids, times and values for the exogenous regressors.\n",
    "    freq : str or int\n",
    "        Frequency of the data. Must be a valid pandas or polars offset alias, or an integer.\n",
    "    season_length : int\n",
    "        Number of observations per unit of time. Ex: 24 Hourly data.\n",
    "    k : int\n",
    "        Maximum order of the fourier terms\n",
    "    h : int (default=0)\n",
    "        Forecast horizon.        \n",
    "    id_col : str (default='unique_id')\n",
    "        Column that identifies each serie.\n",
    "    time_col : str (default='ds')\n",
    "        Column that identifies each timestep, its values can be timestamps or integers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_df : pandas or polars DataFrame\n",
    "        Original DataFrame with the computed features\n",
    "    future_df : pandas or polars DataFrame\n",
    "        DataFrame with future values\n",
    "    \"\"\"\n",
    "    f = partial(_fourier, season_length=season_length, k=k)\n",
    "    return _add_features(\n",
    "        df=df,\n",
    "        freq=freq,\n",
    "        h=h,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        f=f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70b3ed-233c-4ed0-9c50-f2b320236d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from utilsforecast.data import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce8576-d4bd-4864-8ffa-77d50b4a6319",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_series(5, equal_ends=True)\n",
    "transformed_df, future_df = fourier(series, freq='D', season_length=7, k=2, h=1)\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba09cb0-feab-4080-881e-810fbb59400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9619ab-9b6e-433c-b1e9-8de94cf5b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "transformed_df2, future_df2 = fourier(series.sample(frac=1.0), freq='D', season_length=7, k=2, h=1)\n",
    "pd.testing.assert_frame_equal(\n",
    "    transformed_df,\n",
    "    transformed_df2.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    ")\n",
    "pd.testing.assert_frame_equal(future_df, future_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3f99a-2e37-47e4-94f7-10d8f2cf8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| polars\n",
    "import polars as pl\n",
    "import polars.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ae5ca-7220-4cef-872a-7036b20b8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| polars\n",
    "series_pl = generate_series(5, equal_ends=True, engine='polars')\n",
    "transformed_pl, future_pl = fourier(series_pl, freq='1d', season_length=7, k=2, h=1)\n",
    "transformed_pl2, future_pl2 = fourier(series_pl.sample(fraction=1.0), freq='1d', season_length=7, k=2, h=1)\n",
    "pl.testing.assert_frame_equal(transformed_pl, transformed_pl2)\n",
    "pl.testing.assert_frame_equal(future_pl, future_pl2)\n",
    "pd.testing.assert_frame_equal(\n",
    "    transformed_df.drop(columns=['unique_id']),\n",
    "    transformed_pl.drop('unique_id').to_pandas()\n",
    ")\n",
    "pd.testing.assert_frame_equal(\n",
    "    future_df.drop(columns=['unique_id']),\n",
    "    future_pl.drop('unique_id').to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef99e58-df8c-4121-990e-873e66de7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def trend(\n",
    "    df: DFType,\n",
    "    freq: Union[str, int],\n",
    "    h: int = 0,\n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    ") -> Tuple[DFType, DFType]:\n",
    "    \"\"\"Add a trend column with consecutive integers for training and forecasting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Dataframe with ids, times and values for the exogenous regressors.\n",
    "    freq : str or int\n",
    "        Frequency of the data. Must be a valid pandas or polars offset alias, or an integer.\n",
    "    h : int (default=0)\n",
    "        Forecast horizon.        \n",
    "    id_col : str (default='unique_id')\n",
    "        Column that identifies each serie.\n",
    "    time_col : str (default='ds')\n",
    "        Column that identifies each timestep, its values can be timestamps or integers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_df : pandas or polars DataFrame\n",
    "        Original DataFrame with the computed features\n",
    "    future_df : pandas or polars DataFrame\n",
    "        DataFrame with future values\n",
    "    \"\"\"\n",
    "    return _add_features(\n",
    "        df=df,\n",
    "        freq=freq,\n",
    "        h=h,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "        f=_trend,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146556d-7084-4274-9735-cd79da4198e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_series(5, equal_ends=True)\n",
    "transformed_df, future_df = trend(series, freq='D', h=1)\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5901f01-404b-4bc4-91b0-27703f72693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f9894-2fe0-4705-becb-16fead1dfd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _compute_time_feature(\n",
    "    times: Union[pd.Index, pl_Expr],\n",
    "    feature: Union[str, Callable],\n",
    ") -> Tuple[Union[str, List[str]], Union[pd.DataFrame, pl_Expr, List[pl_Expr], pd.Index, np.ndarray]]:\n",
    "    if callable(feature):\n",
    "        feat_vals = feature(times)\n",
    "        if isinstance(feat_vals, pd.DataFrame):\n",
    "            feat_name = feat_vals.columns.tolist()\n",
    "            feat_vals = feat_vals.to_numpy()\n",
    "        else:\n",
    "            feat_name = feature.__name__\n",
    "    else:\n",
    "        feat_name = feature\n",
    "        if isinstance(times, pd.DatetimeIndex):\n",
    "            if feature in (\"week\", \"weekofyear\"):\n",
    "                times = times.isocalendar()\n",
    "            feat_vals = getattr(times, feature).to_numpy()\n",
    "        else:\n",
    "            feat_vals = getattr(times.dt, feature)()\n",
    "    return feat_name, feat_vals\n",
    "\n",
    "def _add_time_features(\n",
    "    df: DFType,\n",
    "    features: List[Union[str, Callable]],\n",
    "    time_col: str = 'ds',\n",
    ") -> DFType:\n",
    "    df = ufp.copy_if_pandas(df, deep=False)\n",
    "    unique_times = df[time_col].unique()\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        times = pd.Index(unique_times)\n",
    "        time2pos = {time: i for i, time in enumerate(times)}\n",
    "        restore_idxs = df[time_col].map(time2pos).to_numpy()\n",
    "        for feature in features:\n",
    "            name, vals = _compute_time_feature(times, feature)\n",
    "            df[name] = vals[restore_idxs]\n",
    "    elif isinstance(df, pl_DataFrame):\n",
    "        exprs = []\n",
    "        for feature in features:\n",
    "            name, vals = _compute_time_feature(pl.col(time_col), feature)\n",
    "            if isinstance(vals, list):\n",
    "                exprs.extend(vals)\n",
    "            else:\n",
    "                assert isinstance(vals, pl_Expr)\n",
    "                exprs.append(vals.alias(name))\n",
    "        feats = unique_times.to_frame().with_columns(*exprs)\n",
    "        df = df.join(feats, on=time_col, how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b01e29-0f60-4598-9f48-b6d541c3aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def time_features(\n",
    "    df: DFType,\n",
    "    freq: Union[str, int],\n",
    "    features: List[Union[str, Callable]],\n",
    "    h: int = 0,\n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',    \n",
    ") -> Tuple[DFType, DFType]:\n",
    "    \"\"\"Compute timestamp-based features for training and forecasting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Dataframe with ids, times and values for the exogenous regressors.\n",
    "    freq : str or int\n",
    "        Frequency of the data. Must be a valid pandas or polars offset alias, or an integer.\n",
    "    features : list of str or callable\n",
    "        Features to compute. Can be string aliases of timestamp attributes or functions to apply to the times.\n",
    "    h : int (default=0)\n",
    "        Forecast horizon.\n",
    "    id_col : str (default='unique_id')\n",
    "        Column that identifies each serie.\n",
    "    time_col : str (default='ds')\n",
    "        Column that identifies each timestep, its values can be timestamps or integers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_df : pandas or polars DataFrame\n",
    "        Original DataFrame with the computed features\n",
    "    future_df : pandas or polars DataFrame\n",
    "        DataFrame with future values\n",
    "    \"\"\"\n",
    "    transformed = _add_time_features(df=df, features=features, time_col=time_col)\n",
    "    if h == 0:\n",
    "        return transformed, type(df)({})\n",
    "    times_by_id = ufp.group_by_agg(df, id_col, {time_col: 'max'}, maintain_order=True)\n",
    "    times_by_id = ufp.sort(times_by_id, id_col)\n",
    "    future = ufp.make_future_dataframe(\n",
    "        uids=times_by_id[id_col],\n",
    "        last_times=times_by_id[time_col],\n",
    "        freq=freq,\n",
    "        h=h,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "    )\n",
    "    future = _add_time_features(df=future, features=features, time_col=time_col)\n",
    "    return transformed, future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1e0f2-11f8-4915-a9d7-2b45f7bcd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df, future_df = time_features(series, freq='D', features=['month', 'day', 'week'], h=1)\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d07f9d-66f3-47c7-8e61-bc8294e58440",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def future_exog_to_historic(\n",
    "    df: DFType,\n",
    "    freq: Union[str, int],\n",
    "    features: List[str],\n",
    "    h: int = 0,\n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',    \n",
    ") -> Tuple[DFType, DFType]:\n",
    "    \"\"\"Turn future exogenous features into historic by shifting them `h` steps.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Dataframe with ids, times and values for the exogenous regressors.\n",
    "    freq : str or int\n",
    "        Frequency of the data. Must be a valid pandas or polars offset alias, or an integer.\n",
    "    features : list of str\n",
    "        Features to be converted into historic.\n",
    "    h : int (default=0)\n",
    "        Forecast horizon.\n",
    "    id_col : str (default='unique_id')\n",
    "        Column that identifies each serie.\n",
    "    time_col : str (default='ds')\n",
    "        Column that identifies each timestep, its values can be timestamps or integers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_df : pandas or polars DataFrame\n",
    "        Original DataFrame with the computed features\n",
    "    future_df : pandas or polars DataFrame\n",
    "        DataFrame with future values\n",
    "    \"\"\"\n",
    "    if h == 0:\n",
    "        return df, type(df)({})\n",
    "    new_feats = ufp.copy_if_pandas(df[[id_col, time_col, *features]])\n",
    "    new_feats = ufp.assign_columns(\n",
    "        new_feats,\n",
    "        time_col,\n",
    "        ufp.offset_times(new_feats[time_col], freq=freq, n=h),\n",
    "    )\n",
    "    df = ufp.drop_columns(df, features)\n",
    "    df = ufp.join(df, new_feats, on=[id_col, time_col], how='left')\n",
    "    times_by_id = ufp.group_by_agg(df, id_col, {time_col: 'max'}, maintain_order=True)\n",
    "    times_by_id = ufp.sort(times_by_id, id_col)\n",
    "    future = ufp.make_future_dataframe(\n",
    "        uids=times_by_id[id_col],\n",
    "        last_times=times_by_id[time_col],\n",
    "        freq=freq,\n",
    "        h=h,\n",
    "        id_col=id_col,\n",
    "        time_col=time_col,\n",
    "    )\n",
    "    future = ufp.join(future, new_feats, on=[id_col, time_col], how='left')\n",
    "    return df, future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66941119-576d-4b06-95f2-5425939d8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_with_prices = series.assign(price=np.random.rand(len(series))).sample(frac=1.0)\n",
    "series_with_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff742dca-4035-44dd-b26d-4ea62c368091",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df, future_df = future_exog_to_historic(\n",
    "    df=series_with_prices, \n",
    "    freq='D',\n",
    "    features=['price'],\n",
    "    h=2,\n",
    ")\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d050e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb9e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "pd.testing.assert_frame_equal(\n",
    "    (\n",
    "        series_with_prices\n",
    "        .sort_values(['unique_id', 'ds'])\n",
    "        .groupby('unique_id', observed=True)\n",
    "        .tail(2)\n",
    "        [['unique_id', 'price']]\n",
    "        .reset_index(drop=True)\n",
    "    ),\n",
    "    future_df[['unique_id', 'price']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| polars\n",
    "series_with_prices_pl = pl.from_pandas(\n",
    "    series_with_prices.astype({'unique_id': 'int64'})\n",
    ")\n",
    "transformed_pl, future_pl = future_exog_to_historic(\n",
    "    df=series_with_prices_pl, \n",
    "    freq='1d',\n",
    "    features=['price'],\n",
    "    h=2,\n",
    ")\n",
    "pd.testing.assert_frame_equal(\n",
    "    future_pl.to_pandas(),\n",
    "    future_df.astype({'unique_id': 'int64'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3307d99-62fd-46b0-856b-ad4cf297b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pipeline(\n",
    "    df: DFType,\n",
    "    features: List[Callable],\n",
    "    freq: Union[str, int],\n",
    "    h: int = 0,\n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    ") -> Tuple[DFType, DFType]:\n",
    "    \"\"\"Compute several features for training and forecasting\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Dataframe with ids, times and values for the exogenous regressors.\n",
    "    features : list of callable\n",
    "        List of features to compute. Must take only df, freq, h, id_col and time_col (other arguments must be fixed).\n",
    "    freq : str or int\n",
    "        Frequency of the data. Must be a valid pandas or polars offset alias, or an integer.\n",
    "    h : int (default=0)\n",
    "        Forecast horizon.        \n",
    "    id_col : str (default='unique_id')\n",
    "        Column that identifies each serie.\n",
    "    time_col : str (default='ds')\n",
    "        Column that identifies each timestep, its values can be timestamps or integers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transformed_df : pandas or polars DataFrame\n",
    "        Original DataFrame with the computed features\n",
    "    future_df : pandas or polars DataFrame\n",
    "        DataFrame with future values\n",
    "    \"\"\"\n",
    "    transformed: Optional[DataFrame] = None\n",
    "    future: Optional[DataFrame] = None\n",
    "    for f in features:\n",
    "        f_transformed, f_future = f(df=df, freq=freq, h=h, id_col=id_col, time_col=time_col)\n",
    "        if transformed is None:\n",
    "            transformed = f_transformed\n",
    "            future = f_future\n",
    "        else:\n",
    "            feat_cols = [c for c in f_future.columns if c not in (id_col, time_col)]\n",
    "            transformed = ufp.horizontal_concat([transformed, f_transformed[feat_cols]])\n",
    "            future = ufp.horizontal_concat([future, f_future[feat_cols]])\n",
    "    return transformed, future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7c6074-096b-4f9c-9f34-79ed65f06e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_weekend(times):\n",
    "    if isinstance(times, pd.Index):\n",
    "        dow = times.weekday + 1  # monday=0 in pandas and 1 in polars\n",
    "    else:\n",
    "        dow = times.dt.weekday()\n",
    "    return dow >= 6\n",
    "\n",
    "def even_days_and_months(times):\n",
    "    if isinstance(times, pd.Index):\n",
    "        out = pd.DataFrame(\n",
    "            {\n",
    "                'even_day': (times.weekday + 1) % 2 == 0,\n",
    "                'even_month': times.month % 2 == 0,\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # for polars you can return a list of expressions\n",
    "        out = [\n",
    "            (times.dt.weekday() % 2 == 0).alias('even_day'),\n",
    "            (times.dt.month() % 2 == 0).alias('even_month'),\n",
    "        ]\n",
    "    return out\n",
    "\n",
    "features = [\n",
    "    trend,\n",
    "    partial(fourier, season_length=7, k=1),\n",
    "    partial(fourier, season_length=28, k=1),\n",
    "    partial(time_features, features=['day', is_weekend, even_days_and_months]),\n",
    "]\n",
    "transformed_df, future_df = pipeline(\n",
    "    series,\n",
    "    features=features,\n",
    "    freq='D',\n",
    "    h=1,\n",
    ")\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c864c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92c960-9ef6-49b7-83d3-cc6a3366c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7d54d-7c73-40f1-a192-8e5816e1ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def reduce_join(dfs, on):\n",
    "    return reduce(\n",
    "        lambda left, right: left.merge(right, on=on, how='left'),\n",
    "        dfs,\n",
    "    )\n",
    "\n",
    "individual_results = [f(series, freq='D', h=1) for f in features]\n",
    "expected_transformed = reduce_join(\n",
    "    [r[0] for r in individual_results], on=['unique_id', 'ds', 'y']\n",
    ")\n",
    "expected_future = reduce_join(\n",
    "    [r[1] for r in individual_results], on=['unique_id', 'ds']\n",
    ")\n",
    "pd.testing.assert_frame_equal(transformed_df, expected_transformed)\n",
    "pd.testing.assert_frame_equal(future_df, expected_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d65447-93e8-4692-ad34-2a21852fb504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| polars\n",
    "transformed_pl, future_pl = pipeline(\n",
    "    series_pl,\n",
    "    features=features,\n",
    "    freq='1d',\n",
    "    h=1,\n",
    ")\n",
    "pd.testing.assert_frame_equal(\n",
    "    transformed_pl.drop('unique_id').to_pandas(),\n",
    "    transformed_df.drop(columns='unique_id'),\n",
    "    check_dtype=False,\n",
    ")\n",
    "pd.testing.assert_frame_equal(\n",
    "    future_pl.drop('unique_id').to_pandas(),\n",
    "    future_df.drop(columns='unique_id'),\n",
    "    check_dtype=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
