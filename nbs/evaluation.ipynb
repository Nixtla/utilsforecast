{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aace6e9-4c24-4e66-b786-f468e32227a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797ba46-9482-49b2-8b03-77a9acf830bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313a375-be8b-49b8-b76e-46e130d2e686",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "> Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aeefe7-23ed-43f0-8abf-69ac2f3442b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect\n",
    "import re\n",
    "import reprlib\n",
    "from typing import Callable, Dict, List, Optional, get_origin\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utilsforecast.processing as ufp\n",
    "from utilsforecast.compat import DataFrame, pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ce6a6-934b-4f7f-bc15-a3713004c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _function_name(f: Callable):\n",
    "    if hasattr(f, 'func'):\n",
    "        # partial fn\n",
    "        name = f.func.__name__\n",
    "    else:\n",
    "        name = f.__name__\n",
    "    return name\n",
    "\n",
    "def _quantiles_from_levels(level: List[int]) -> np.ndarray:\n",
    "    \"\"\"Returns quantiles associated to `level` and the sorte columns of `model_name`\"\"\"\n",
    "    level = sorted(level)\n",
    "    alphas = [100 - lv for lv in level]\n",
    "    quantiles = [alpha / 200 for alpha in reversed(alphas)]\n",
    "    quantiles.extend([1 - alpha / 200 for alpha in alphas])\n",
    "    return np.array(quantiles)\n",
    "\n",
    "def _models_from_levels(model_name: str, level: List[int]) -> List[str]:\n",
    "    cols = [f'{model_name}-lo-{lv}' for lv in reversed(level)]\n",
    "    cols.extend([f'{model_name}-hi-{lv}' for lv in level])\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67cedf-716d-4adb-b81a-ee18350dce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate(\n",
    "    df: DataFrame,\n",
    "    metrics: List[Callable],\n",
    "    models: Optional[List[str]] = None,\n",
    "    train_df: Optional[DataFrame] = None,\n",
    "    level: Optional[List[int]] = None,\n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    target_col: str = 'y',\n",
    "    reduce_stat: Optional[str] = None,\n",
    ") -> DataFrame:\n",
    "    \"\"\"Evaluate forecast using different metrics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Forecasts to evaluate.\n",
    "        Must have `id_col`, `time_col`, `target_col` and models' predictions.\n",
    "    metrics : list of callable\n",
    "        Functions with arguments `df`, `models`, `id_col`, `target_col` and optionally `train_df`.\n",
    "    models : list of str, optional (default=None)\n",
    "        Names of the models to evaluate.\n",
    "        If `None` will use every column in the dataframe after removing id, time and target.\n",
    "    train_df : pandas DataFrame, optional (default=None)\n",
    "        Training set. Used to evaluate metrics such as `mase`.\n",
    "    level : list of int, optional (default=None)\n",
    "        Prediction interval levels. Used to compute losses that rely on quantiles.\n",
    "    id_col : str (default='unique_id')\n",
    "        Column that identifies each serie.\n",
    "    time_col : str (default='ds')\n",
    "        Column that identifies each timestep, its values can be timestamps or integers.\n",
    "    target_col : str (default='y')\n",
    "        Column that contains the target.\n",
    "    reduce_stat : str, optional (default=None)\n",
    "        Statistic to compute on the scores by id to reduce them to a single number.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas or polars DataFrame\n",
    "        Metrics with one row per (id, metric) combination and one column per model.\n",
    "        If `reduce_stat` is not `None`, there is only one row per metric.\n",
    "    \"\"\"\n",
    "    if models is None:\n",
    "        model_cols = [\n",
    "            c for c in df.columns\n",
    "            if c not in [id_col, time_col, target_col]\n",
    "            and not re.search(r'-(?:lo|hi)-\\d+', c)\n",
    "        ]\n",
    "    else:\n",
    "        model_cols = models\n",
    "\n",
    "    # interval cols\n",
    "    if level is not None:\n",
    "        expected_cols = {\n",
    "            f'{m}-{side}-{lvl}'\n",
    "            for m in model_cols\n",
    "            for side in ('lo', 'hi')\n",
    "            for lvl in level\n",
    "        }\n",
    "        missing = expected_cols - set(df.columns)\n",
    "        if missing:\n",
    "            raise ValueError(\n",
    "                f\"The following columns are required for level={level} \"\n",
    "                f\"and are missing: {missing}\"\n",
    "            )\n",
    "    else:\n",
    "        requires_level = [\n",
    "            m for m in metrics\n",
    "            if get_origin(inspect.signature(m).parameters['models'].annotation) is dict\n",
    "        ]\n",
    "        if requires_level:\n",
    "            raise ValueError(\n",
    "                f\"The following metrics require setting `level`: {requires_level}\"\n",
    "            )\n",
    "\n",
    "    # y_train\n",
    "    metric_requires_y_train = {_function_name(m): 'train_df' in inspect.signature(m).parameters for m in metrics}\n",
    "    y_train_metrics = [m for m, requires_yt in metric_requires_y_train.items() if requires_yt]\n",
    "    if y_train_metrics:\n",
    "        if train_df is None:\n",
    "            raise ValueError(\n",
    "                f'The following metrics require y_train: {y_train_metrics}. '\n",
    "                'Please provide `train_df`.'\n",
    "            )\n",
    "        if isinstance(train_df, pd.DataFrame):\n",
    "            train_df = train_df.sort_values([id_col, time_col])\n",
    "        else:\n",
    "            train_df = train_df.sort([id_col, time_col])\n",
    "        missing_series = set(df[id_col].unique()) - set(train_df[id_col].unique())\n",
    "        if missing_series:\n",
    "            raise ValueError(\n",
    "                f\"The following series are missing from the train_df: {reprlib.repr(missing_series)}\"\n",
    "            )\n",
    "\n",
    "    results_per_metric = []\n",
    "    for metric in metrics:\n",
    "        metric_name = _function_name(metric)\n",
    "        kwargs = dict(\n",
    "            df=df,\n",
    "            models=model_cols,\n",
    "            id_col=id_col,\n",
    "            target_col=target_col\n",
    "        )\n",
    "        if metric_requires_y_train[metric_name]:\n",
    "            kwargs['train_df'] = train_df\n",
    "        metric_params = inspect.signature(metric).parameters\n",
    "        if 'q' in metric_params or metric_params['models'].annotation is Dict[str, str]:\n",
    "            assert level is not None  # we've already made sure of this above\n",
    "            for lvl in level:\n",
    "                quantiles = _quantiles_from_levels([lvl])\n",
    "                for q, side in zip(quantiles, ['lo', 'hi']):\n",
    "                    kwargs['models'] = {model: f'{model}-{side}-{lvl}' for model in model_cols}\n",
    "                    if 'q' in metric_params:\n",
    "                        # this is for calibration, since it uses the predictions for q \n",
    "                        # but doesn't use it\n",
    "                        kwargs['q'] = q\n",
    "                    result = metric(**kwargs)\n",
    "                    result = ufp.assign_columns(result, 'metric', f'{metric_name}_q{q}')\n",
    "                    results_per_metric.append(result)\n",
    "        elif 'quantiles' in metric_params:\n",
    "            assert level is not None  # we've already made sure of this above\n",
    "            quantiles = _quantiles_from_levels(level)\n",
    "            kwargs['quantiles'] = quantiles            \n",
    "            kwargs['models'] = {model: _models_from_levels(model, level) for model in model_cols}\n",
    "            result = metric(**kwargs)\n",
    "            result = ufp.assign_columns(result, 'metric', metric_name)\n",
    "            results_per_metric.append(result)\n",
    "        elif 'level' in metric_params:\n",
    "            assert level is not None  # we've already made sure of this above\n",
    "            for lvl in level:\n",
    "                kwargs['level'] = lvl\n",
    "                result = metric(**kwargs)\n",
    "                result = ufp.assign_columns(result, 'metric', f'{metric_name}_level{lvl}')\n",
    "                results_per_metric.append(result)\n",
    "        else:\n",
    "            result = metric(**kwargs)\n",
    "            result = ufp.assign_columns(result, 'metric', metric_name)\n",
    "            results_per_metric.append(result)\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = pd.concat(results_per_metric).reset_index(drop=True)\n",
    "    else:\n",
    "        df = pl.concat(results_per_metric, how=\"diagonal\")\n",
    "    id_cols = [id_col, \"metric\"]\n",
    "    model_cols = [c for c in df.columns if c not in id_cols]\n",
    "    df = df[id_cols + model_cols]\n",
    "    if reduce_stat is not None:\n",
    "        df = ufp.group_by_agg(\n",
    "            df,\n",
    "            by='metric',\n",
    "            aggs={m: reduce_stat for m in model_cols},\n",
    "            maintain_order=True,\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9145d9-f5f7-417b-9264-717d0886a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf35141-7368-46ee-a6b6-e6fa0b8c9e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/utilsforecast/blob/main/utilsforecast/evaluation.py#L43){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### evaluate\n",
       "\n",
       ">      evaluate\n",
       ">                (df:Union[pandas.core.frame.DataFrame,polars.dataframe.frame.Da\n",
       ">                taFrame], metrics:List[Callable],\n",
       ">                models:Optional[List[str]]=None, train_df:Union[pandas.core.fra\n",
       ">                me.DataFrame,polars.dataframe.frame.DataFrame,NoneType]=None,\n",
       ">                level:Optional[List[int]]=None, id_col:str='unique_id',\n",
       ">                time_col:str='ds', target_col:str='y',\n",
       ">                reduce_stat:Optional[str]=None)\n",
       "\n",
       "*Evaluate forecast using different metrics.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | Union |  | Forecasts to evaluate.<br>Must have `id_col`, `time_col`, `target_col` and models' predictions. |\n",
       "| metrics | List |  | Functions with arguments `df`, `models`, `id_col`, `target_col` and optionally `train_df`. |\n",
       "| models | Optional | None | Names of the models to evaluate.<br>If `None` will use every column in the dataframe after removing id, time and target. |\n",
       "| train_df | Union | None | Training set. Used to evaluate metrics such as `mase`. |\n",
       "| level | Optional | None | Prediction interval levels. Used to compute losses that rely on quantiles. |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| reduce_stat | Optional | None | Statistic to compute on the scores by id to reduce them to a single number. |\n",
       "| **Returns** | **Union** |  | **Metrics with one row per (id, metric) combination and one column per model.<br>If `reduce_stat` is not `None`, there is only one row per metric.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/utilsforecast/blob/main/utilsforecast/evaluation.py#L43){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### evaluate\n",
       "\n",
       ">      evaluate\n",
       ">                (df:Union[pandas.core.frame.DataFrame,polars.dataframe.frame.Da\n",
       ">                taFrame], metrics:List[Callable],\n",
       ">                models:Optional[List[str]]=None, train_df:Union[pandas.core.fra\n",
       ">                me.DataFrame,polars.dataframe.frame.DataFrame,NoneType]=None,\n",
       ">                level:Optional[List[int]]=None, id_col:str='unique_id',\n",
       ">                time_col:str='ds', target_col:str='y',\n",
       ">                reduce_stat:Optional[str]=None)\n",
       "\n",
       "*Evaluate forecast using different metrics.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| df | Union |  | Forecasts to evaluate.<br>Must have `id_col`, `time_col`, `target_col` and models' predictions. |\n",
       "| metrics | List |  | Functions with arguments `df`, `models`, `id_col`, `target_col` and optionally `train_df`. |\n",
       "| models | Optional | None | Names of the models to evaluate.<br>If `None` will use every column in the dataframe after removing id, time and target. |\n",
       "| train_df | Union | None | Training set. Used to evaluate metrics such as `mase`. |\n",
       "| level | Optional | None | Prediction interval levels. Used to compute losses that rely on quantiles. |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| reduce_stat | Optional | None | Statistic to compute on the scores by id to reduce them to a single number. |\n",
       "| **Returns** | **Union** |  | **Metrics with one row per (id, metric) combination and one column per model.<br>If `reduce_stat` is not `None`, there is only one row per metric.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e59b0a-e085-46b6-82c1-a5bb4ff6c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utilsforecast.losses import *\n",
    "from utilsforecast.data import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da8fe30-f0bd-4c8f-ab53-22ef168f6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_series(10, n_models=2, level=[80, 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b6194-3790-4caf-8e12-6f4f96e4a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "series['unique_id'] = series['unique_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb6bad4-177c-44d7-81f8-96dff38ca5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['model0', 'model1']\n",
    "metrics = [\n",
    "    mae,\n",
    "    mse,\n",
    "    rmse,\n",
    "    mape,\n",
    "    smape,\n",
    "    partial(mase, seasonality=7),\n",
    "    quantile_loss,\n",
    "    mqloss,\n",
    "    coverage,\n",
    "    calibration,\n",
    "    scaled_crps,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7a7d1-afeb-4e90-98a2-dae1f1fc10e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>metric</th>\n",
       "      <th>model0</th>\n",
       "      <th>model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.158108</td>\n",
       "      <td>0.163246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.160109</td>\n",
       "      <td>0.143805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.159815</td>\n",
       "      <td>0.170510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.168537</td>\n",
       "      <td>0.161595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.170182</td>\n",
       "      <td>0.163329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5</td>\n",
       "      <td>scaled_crps</td>\n",
       "      <td>0.034202</td>\n",
       "      <td>0.035472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>6</td>\n",
       "      <td>scaled_crps</td>\n",
       "      <td>0.034880</td>\n",
       "      <td>0.033610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>7</td>\n",
       "      <td>scaled_crps</td>\n",
       "      <td>0.034337</td>\n",
       "      <td>0.034745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>8</td>\n",
       "      <td>scaled_crps</td>\n",
       "      <td>0.033336</td>\n",
       "      <td>0.032459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>9</td>\n",
       "      <td>scaled_crps</td>\n",
       "      <td>0.034766</td>\n",
       "      <td>0.035243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_id       metric    model0    model1\n",
       "0            0          mae  0.158108  0.163246\n",
       "1            1          mae  0.160109  0.143805\n",
       "2            2          mae  0.159815  0.170510\n",
       "3            3          mae  0.168537  0.161595\n",
       "4            4          mae  0.170182  0.163329\n",
       "..         ...          ...       ...       ...\n",
       "175          5  scaled_crps  0.034202  0.035472\n",
       "176          6  scaled_crps  0.034880  0.033610\n",
       "177          7  scaled_crps  0.034337  0.034745\n",
       "178          8  scaled_crps  0.033336  0.032459\n",
       "179          9  scaled_crps  0.034766  0.035243\n",
       "\n",
       "[180 rows x 4 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = evaluate(\n",
    "    series,\n",
    "    metrics=metrics,\n",
    "    models=models,\n",
    "    train_df=series,\n",
    "    level=[80, 95],\n",
    ")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a297d2-e563-463b-95c9-94273d20da0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model0</th>\n",
       "      <th>model1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calibration_q0.025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calibration_q0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calibration_q0.9</td>\n",
       "      <td>0.833993</td>\n",
       "      <td>0.815833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>calibration_q0.975</td>\n",
       "      <td>0.853991</td>\n",
       "      <td>0.836949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coverage_level80</td>\n",
       "      <td>0.833993</td>\n",
       "      <td>0.815833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coverage_level95</td>\n",
       "      <td>0.853991</td>\n",
       "      <td>0.836949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mae</td>\n",
       "      <td>0.161286</td>\n",
       "      <td>0.162281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mape</td>\n",
       "      <td>0.048894</td>\n",
       "      <td>0.049624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mase</td>\n",
       "      <td>0.966846</td>\n",
       "      <td>0.975354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mqloss</td>\n",
       "      <td>0.056904</td>\n",
       "      <td>0.056216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.048653</td>\n",
       "      <td>0.049198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>quantile_loss_q0.025</td>\n",
       "      <td>0.019990</td>\n",
       "      <td>0.019474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>quantile_loss_q0.1</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>0.065781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>quantile_loss_q0.9</td>\n",
       "      <td>0.095510</td>\n",
       "      <td>0.093841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>quantile_loss_q0.975</td>\n",
       "      <td>0.044803</td>\n",
       "      <td>0.045767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.220357</td>\n",
       "      <td>0.221543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>scaled_crps</td>\n",
       "      <td>0.035003</td>\n",
       "      <td>0.034576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>smape</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.024902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  metric    model0    model1\n",
       "0     calibration_q0.025  0.000000  0.000000\n",
       "1       calibration_q0.1  0.000000  0.000000\n",
       "2       calibration_q0.9  0.833993  0.815833\n",
       "3     calibration_q0.975  0.853991  0.836949\n",
       "4       coverage_level80  0.833993  0.815833\n",
       "5       coverage_level95  0.853991  0.836949\n",
       "6                    mae  0.161286  0.162281\n",
       "7                   mape  0.048894  0.049624\n",
       "8                   mase  0.966846  0.975354\n",
       "9                 mqloss  0.056904  0.056216\n",
       "10                   mse  0.048653  0.049198\n",
       "11  quantile_loss_q0.025  0.019990  0.019474\n",
       "12    quantile_loss_q0.1  0.067315  0.065781\n",
       "13    quantile_loss_q0.9  0.095510  0.093841\n",
       "14  quantile_loss_q0.975  0.044803  0.045767\n",
       "15                  rmse  0.220357  0.221543\n",
       "16           scaled_crps  0.035003  0.034576\n",
       "17                 smape  0.024475  0.024902"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = evaluation.drop(columns='unique_id').groupby('metric').mean().reset_index()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76454324-4e83-4c67-9704-779a5ce3dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| polars\n",
    "import polars.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabea06-1eef-495e-8243-63704187b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| polars\n",
    "series_pl = generate_series(10, n_models=2, level=[80, 95], engine='polars')\n",
    "pl_evaluation = (\n",
    "    evaluate(\n",
    "        series_pl,\n",
    "        metrics=metrics,\n",
    "        train_df=series_pl,\n",
    "        level=[80, 95],\n",
    "    ).drop('unique_id')\n",
    ")\n",
    "pl_summary = ufp.group_by(pl_evaluation, 'metric').mean()\n",
    "pd.testing.assert_frame_equal(\n",
    "    summary.sort_values('metric'),\n",
    "    pl_summary.sort('metric').to_pandas(),\n",
    ")\n",
    "pl.testing.assert_frame_equal(\n",
    "    evaluate(\n",
    "        series_pl, metrics=metrics, train_df=series_pl, level=[80, 95], reduce_stat='mean'\n",
    "    ).sort('metric'),\n",
    "    pl_summary.sort('metric'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec36953-e647-4651-9717-b798284b2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| datasets\n",
    "from datasetsforecast.evaluation import accuracy as ds_evaluate\n",
    "import datasetsforecast.losses as ds_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9136a1-59f3-485d-813e-e0e29432f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| datasets\n",
    "def daily_mase(y, y_hat, y_train):\n",
    "    return ds_losses.mase(y, y_hat, y_train, seasonality=7)\n",
    "\n",
    "for reduce_stat in [None, 'mean']:\n",
    "    uf_res = evaluate(\n",
    "        series,\n",
    "        metrics=metrics,\n",
    "        models=models,\n",
    "        train_df=series,\n",
    "        level=[80, 95],\n",
    "        reduce_stat=reduce_stat,\n",
    "    )\n",
    "    agg_by = None if reduce_stat == 'mean' else ['unique_id']\n",
    "    ds_res = ds_evaluate(\n",
    "        series,\n",
    "        metrics=[\n",
    "            ds_losses.mae,\n",
    "            ds_losses.mse,\n",
    "            ds_losses.rmse,\n",
    "            ds_losses.mape,\n",
    "            daily_mase,\n",
    "            ds_losses.smape,\n",
    "            ds_losses.quantile_loss,        \n",
    "            ds_losses.mqloss,\n",
    "            ds_losses.coverage,        \n",
    "            ds_losses.calibration,\n",
    "            ds_losses.scaled_crps,\n",
    "        ],\n",
    "        level=[80, 95],\n",
    "        Y_df=series,\n",
    "        agg_by=agg_by,\n",
    "    )\n",
    "    ds_res['metric'] = ds_res['metric'].str.replace('-', '_')\n",
    "    ds_res['metric'] = ds_res['metric'].str.replace('q_', 'q')\n",
    "    ds_res['metric'] = ds_res['metric'].str.replace('lv_', 'level')\n",
    "    ds_res['metric'] = ds_res['metric'].str.replace('daily_mase', 'mase')\n",
    "    # utils doesn't multiply pct metrics by 100\n",
    "    ds_res.loc[ds_res['metric'].str.startswith('coverage'), ['model0', 'model1']] /= 100\n",
    "    ds_res.loc[ds_res['metric'].eq('mape'), ['model0', 'model1']] /= 100\n",
    "    # we report smape between 0 and 1 instead of 0-200\n",
    "    ds_res.loc[ds_res['metric'].eq('smape'), ['model0', 'model1']] /= 200\n",
    "\n",
    "    ds_res = ds_res[uf_res.columns]\n",
    "    if reduce_stat is None:\n",
    "        ds_res = ds_res.sort_values(['unique_id', 'metric'])\n",
    "        uf_res = uf_res.sort_values(['unique_id', 'metric'])\n",
    "    else:\n",
    "        ds_res = ds_res.sort_values('metric')\n",
    "        uf_res = uf_res.sort_values('metric')\n",
    "    \n",
    "    pd.testing.assert_frame_equal(\n",
    "        uf_res.reset_index(drop=True),\n",
    "        ds_res.reset_index(drop=True),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
