{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aace6e9-4c24-4e66-b786-f468e32227a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797ba46-9482-49b2-8b03-77a9acf830bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313a375-be8b-49b8-b76e-46e130d2e686",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "> Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aeefe7-23ed-43f0-8abf-69ac2f3442b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utilsforecast.compat import DataFrame, pl_DataFrame, pl_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67cedf-716d-4adb-b81a-ee18350dce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def evaluate(\n",
    "    y_hat_df: DataFrame,\n",
    "    metrics: List[Callable],\n",
    "    models: Optional[List[str]] = None,\n",
    "    _y_train_df: Optional[DataFrame] = None,\n",
    "    id_col: str = 'unique_id',\n",
    "    time_col: str = 'ds',\n",
    "    target_col: str = 'y',\n",
    ") -> DataFrame:\n",
    "    \"\"\"Evaluate forecast using different metrics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_hat_df : pandas or polars DataFrame\n",
    "        Forecasts to evaluate.\n",
    "        Must have `id_col`, `time_col`, `target_col` and models' predictions.\n",
    "    metrics : list of callable\n",
    "        Functions with arguments `y`, `y_hat`, and optionally `y_train`.\n",
    "    models : list of str, optional (default=None)\n",
    "        Names of the models to evaluate.\n",
    "        If `None` will use every column in the dataframe removing id, time and target.\n",
    "    y_train_df : pandas DataFrame, optional (default=None)\n",
    "        Training set. Used to evaluate metrics such as `mase`. \n",
    "    id_col : str (default='unique_id')\n",
    "        Column that identifies each serie. If 'index' then the index is used.\n",
    "    time_col : str (default='ds')\n",
    "        Column that identifies each timestep, its values can be timestamps or integers.\n",
    "    target_col : str (default='y')\n",
    "        Column that contains the target.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas or polars DataFrame\n",
    "        Metrics with one row per (id, metric) combination and one column per model.\n",
    "    \"\"\"\n",
    "    is_pandas = isinstance(y_hat_df, pd.DataFrame)\n",
    "    if is_pandas:\n",
    "        assert isinstance(y_hat_df, pd.DataFrame)  # mypy\n",
    "        y_hat_df = y_hat_df.sort_values([id_col, time_col])\n",
    "    else:\n",
    "        y_hat_df = y_hat_df.sort([id_col, time_col])\n",
    "    if models is None:\n",
    "        model_cols = [c for c in y_hat_df.columns if c not in [id_col, time_col, target_col]]\n",
    "    else:\n",
    "        model_cols = models\n",
    "    targets = y_hat_df[target_col].to_numpy()\n",
    "    predictions = y_hat_df[model_cols].to_numpy().T\n",
    "    sizes = y_hat_df[id_col].value_counts()\n",
    "    if is_pandas:\n",
    "        sizes = sizes.rename('counts').sort_index().reset_index()\n",
    "    else:\n",
    "        sizes = sizes.sort(id_col)\n",
    "    indptr = np.append(np.uint32(0), sizes['counts'].to_numpy().cumsum())\n",
    "    n_series = len(indptr) - 1\n",
    "    results_per_metric = []\n",
    "    for metric in metrics:\n",
    "        results = {id_col: sizes[id_col], 'metric': metric.__name__}\n",
    "        for i, model in enumerate(model_cols):\n",
    "            model_results = np.empty(n_series)\n",
    "            for j in range(n_series):\n",
    "                sl = slice(indptr[j], indptr[j + 1])\n",
    "                model_results[j] = metric(targets[sl], predictions[i, sl])\n",
    "            results[model] = model_results\n",
    "        df = pd.DataFrame(results) if is_pandas else pl_DataFrame(results)\n",
    "        results_per_metric.append(df)\n",
    "    if is_pandas:\n",
    "        df = pd.concat(results_per_metric)\n",
    "    else:\n",
    "        df = pl_concat(results_per_metric)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9145d9-f5f7-417b-9264-717d0886a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf35141-7368-46ee-a6b6-e6fa0b8c9e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### evaluate\n",
       "\n",
       ">      evaluate (y_hat_df:Union[pandas.core.frame.DataFrame,polars.dataframe.fra\n",
       ">                me.DataFrame], metrics:List[Callable],\n",
       ">                models:Optional[List[str]]=None, y_train_df:Union[pandas.core.f\n",
       ">                rame.DataFrame,polars.dataframe.frame.DataFrame,NoneType]=None,\n",
       ">                id_col:str='unique_id', time_col:str='ds', target_col:str='y')\n",
       "\n",
       "Evaluate forecast using different metrics.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| y_hat_df | Union |  | Forecasts to evaluate.<br>Must have `id_col`, `time_col`, `target_col` and models' predictions. |\n",
       "| metrics | List |  | Functions with arguments `y`, `y_hat`, and optionally `y_train`. |\n",
       "| models | Optional | None | Names of the models to evaluate.<br>If `None` will use every column in the dataframe removing id, time and target. |\n",
       "| y_train_df | Union | None | Training set. Used to evaluate metrics such as `mase`.  |\n",
       "| id_col | str | unique_id | Column that identifies each serie. If 'index' then the index is used. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| **Returns** | **Union** |  | **Metrics with one row per (id, metric) combination and one column per model.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### evaluate\n",
       "\n",
       ">      evaluate (y_hat_df:Union[pandas.core.frame.DataFrame,polars.dataframe.fra\n",
       ">                me.DataFrame], metrics:List[Callable],\n",
       ">                models:Optional[List[str]]=None, y_train_df:Union[pandas.core.f\n",
       ">                rame.DataFrame,polars.dataframe.frame.DataFrame,NoneType]=None,\n",
       ">                id_col:str='unique_id', time_col:str='ds', target_col:str='y')\n",
       "\n",
       "Evaluate forecast using different metrics.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| y_hat_df | Union |  | Forecasts to evaluate.<br>Must have `id_col`, `time_col`, `target_col` and models' predictions. |\n",
       "| metrics | List |  | Functions with arguments `y`, `y_hat`, and optionally `y_train`. |\n",
       "| models | Optional | None | Names of the models to evaluate.<br>If `None` will use every column in the dataframe removing id, time and target. |\n",
       "| y_train_df | Union | None | Training set. Used to evaluate metrics such as `mase`.  |\n",
       "| id_col | str | unique_id | Column that identifies each serie. If 'index' then the index is used. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |\n",
       "| **Returns** | **Union** |  | **Metrics with one row per (id, metric) combination and one column per model.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e59b0a-e085-46b6-82c1-a5bb4ff6c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "from utilsforecast.losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94faf40-1189-4ade-80b0-44223939a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.read_csv('submission.csv')\n",
    "subm = subm.melt(id_vars=['id'])\n",
    "subm['model1'] = subm['value'] * 0.1 * np.random.rand(subm.shape[0])\n",
    "subm['model2'] = subm['value'] * 0.1 * np.random.rand(subm.shape[0])\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1ed61-ce4c-4e27-8528-d6279e7884d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 129 ms, total: 13.8 s\n",
      "Wall time: 13.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>metric</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.693528</td>\n",
       "      <td>0.686560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_2_evaluation</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.829257</td>\n",
       "      <td>0.815626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_001_CA_2_validation</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_001_CA_3_evaluation</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.934637</td>\n",
       "      <td>0.934619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id metric    model1    model2\n",
       "0  FOODS_1_001_CA_1_evaluation    mae  0.693528  0.686560\n",
       "1  FOODS_1_001_CA_1_validation    mae  0.000000  0.000000\n",
       "2  FOODS_1_001_CA_2_evaluation    mae  0.829257  0.815626\n",
       "3  FOODS_1_001_CA_2_validation    mae  0.000000  0.000000\n",
       "4  FOODS_1_001_CA_3_evaluation    mae  0.934637  0.934619"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time evaluate(subm, metrics=[mape, smape, rmse, mae], id_col='id', time_col='variable', target_col='value').sort_values(['metric', 'id']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80747b46-8e85-4d56-8723-4c8917bdcdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_df = pl.from_pandas(subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ab1f1-d3ef-4745-a08a-5774fae2d2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 s, sys: 262 ms, total: 14.3 s\n",
      "Wall time: 13 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>metric</th><th>model1</th><th>model2</th></tr><tr><td>str</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;FOODS_1_001_CA…</td><td>&quot;mae&quot;</td><td>0.693528</td><td>0.68656</td></tr><tr><td>&quot;FOODS_1_001_CA…</td><td>&quot;mae&quot;</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;FOODS_1_001_CA…</td><td>&quot;mae&quot;</td><td>0.829257</td><td>0.815626</td></tr><tr><td>&quot;FOODS_1_001_CA…</td><td>&quot;mae&quot;</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;FOODS_1_001_CA…</td><td>&quot;mae&quot;</td><td>0.934637</td><td>0.934619</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────────────────┬────────┬──────────┬──────────┐\n",
       "│ id                          ┆ metric ┆ model1   ┆ model2   │\n",
       "│ ---                         ┆ ---    ┆ ---      ┆ ---      │\n",
       "│ str                         ┆ str    ┆ f64      ┆ f64      │\n",
       "╞═════════════════════════════╪════════╪══════════╪══════════╡\n",
       "│ FOODS_1_001_CA_1_evaluation ┆ mae    ┆ 0.693528 ┆ 0.68656  │\n",
       "│ FOODS_1_001_CA_1_validation ┆ mae    ┆ 0.0      ┆ 0.0      │\n",
       "│ FOODS_1_001_CA_2_evaluation ┆ mae    ┆ 0.829257 ┆ 0.815626 │\n",
       "│ FOODS_1_001_CA_2_validation ┆ mae    ┆ 0.0      ┆ 0.0      │\n",
       "│ FOODS_1_001_CA_3_evaluation ┆ mae    ┆ 0.934637 ┆ 0.934619 │\n",
       "└─────────────────────────────┴────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time evaluate(pl_df, metrics=[mape, smape, rmse, mae], id_col='id', time_col='variable', target_col='value').sort(['metric', 'id']).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
