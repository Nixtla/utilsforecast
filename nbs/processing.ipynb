{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9284ac-4d6c-42fc-8d05-13ff8fa7460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d96e02b-4e1b-4284-8808-58c7dbb1fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133caf6-09b0-4de3-b168-b7cff92040a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BaseOffset\n",
    "\n",
    "from utilsforecast.compat import DataFrame, Series, pl, pl_DataFrame, pl_Series\n",
    "from utilsforecast.validation import validate_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970c3e9-b00a-4485-a8de-26471d515e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq\n",
    "from nbdev import show_doc\n",
    "\n",
    "from utilsforecast.compat import POLARS_INSTALLED\n",
    "from utilsforecast.data import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688032bd-838d-4086-be34-d0b02590a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _polars_categorical_to_numerical(serie: pl_Series) -> pl_Series:\n",
    "    if serie.dtype == pl.Categorical:\n",
    "        serie = serie.to_physical()\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04df186-1663-45b9-90ed-cdec91a137fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_numpy(df: DataFrame) -> np.ndarray:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        cat_cols = [c for c, dtype in df.dtypes.items() if isinstance(dtype, pd.CategoricalDtype)]\n",
    "        if cat_cols:\n",
    "            df = df.copy(deep=False)\n",
    "            for col in cat_cols:\n",
    "                df[col] = df[col].cat.codes\n",
    "        df = df.to_numpy()\n",
    "    elif isinstance(df, pl.DataFrame):\n",
    "        try:\n",
    "            expr = pl.all().map_batches(_polars_categorical_to_numerical)\n",
    "        except AttributeError:\n",
    "            expr = pl.all().map(_polars_categorical_to_numerical)\n",
    "        df = df.select(expr).to_numpy(order='c')\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df)} is not supported\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73199e1f-2104-47c5-9415-07b20e8a61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def counts_by_id(df: DataFrame, id_col: str) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        id_counts = df.groupby(id_col, observed=True).size()\n",
    "        if not id_counts.index.is_monotonic_increasing:\n",
    "            id_counts = id_counts.sort_index()\n",
    "        id_counts = id_counts.reset_index()\n",
    "        id_counts.columns = [id_col, 'counts']\n",
    "    elif isinstance(df, pl.DataFrame):\n",
    "        id_counts = df[id_col].value_counts().sort(id_col)\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df)} is not supported\")\n",
    "    return id_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29656557-2fb3-420f-ba19-fdc118118ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def maybe_compute_sort_indices(\n",
    "    df: DataFrame, id_col: str, time_col: str\n",
    ") -> Union[Optional[np.ndarray], Optional[pd.Series]]:\n",
    "    \"\"\"Compute indices that would sort dataframe\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Input dataframe with id, times and target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array or None\n",
    "        Array with indices to sort the dataframe or None if it's already sorted.\n",
    "    \"\"\"\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        idx = pd.MultiIndex.from_frame(df[[id_col, time_col]])\n",
    "    elif isinstance(df, pl.DataFrame):\n",
    "        # this was faster than trying to build the multi index from polars\n",
    "        sort_idxs = df.select(pl.arg_sort_by([id_col, time_col]).alias('idx'))['idx']\n",
    "        idx = pd.Index(sort_idxs.to_numpy())\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df)} is not supported\")\n",
    "    if idx.is_monotonic_increasing:\n",
    "        return None\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        sort_idxs = idx.argsort()\n",
    "    return sort_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc46c8b-8aeb-4a0f-be20-5db503cf03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assign_columns(df: DataFrame, names: Union[str, List[str]], values: Union[np.ndarray, pd.Series, pl_Series]) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df[names] = values\n",
    "    elif isinstance(df, pl.DataFrame):\n",
    "        is_scalar = isinstance(values, str) or not hasattr(values, '__len__')\n",
    "        if is_scalar:\n",
    "            assert isinstance(names, str)\n",
    "            vals: Union[pl_DataFrame, pl_Series, pl.Expr] = pl.lit(values).alias(names)\n",
    "        elif isinstance(values, pl_Series):\n",
    "            assert isinstance(names, str)\n",
    "            vals = values.alias(names)\n",
    "        else:\n",
    "            if isinstance(names, str):\n",
    "                names = [names]\n",
    "            vals = pl.from_numpy(values, schema=names)\n",
    "        df = df.with_columns(vals)\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df)} is not supported\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb147d-7aba-49d9-b741-aff36be7caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = ['pandas']\n",
    "if POLARS_INSTALLED:\n",
    "    engines.append('polars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb9058-3993-4881-82fa-4fbe874ab56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    x = np.random.rand(series.shape[0])    \n",
    "    series = assign_columns(series, 'x', x)\n",
    "    series = assign_columns(series, ['y', 'z'], np.vstack([x, x]).T)\n",
    "    series = assign_columns(series, 'ones', 1)\n",
    "    series = assign_columns(series, 'zeros', np.zeros(series.shape[0]))\n",
    "    series = assign_columns(series, 'as', 'a')\n",
    "    np.testing.assert_allclose(\n",
    "        series[['x', 'y', 'z']],\n",
    "        np.vstack([x, x, x]).T\n",
    "    )\n",
    "    np.testing.assert_equal(series['ones'], np.ones(series.shape[0]))\n",
    "    np.testing.assert_equal(series['as'], np.full(series.shape[0], 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e41bbb-a541-4957-8c28-7af820488f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def take_rows(df: Union[DataFrame, Series, np.ndarray], idxs: np.ndarray) -> DataFrame:\n",
    "    if isinstance(df, (pd.DataFrame, pd.Series)):\n",
    "        df = df.iloc[idxs]\n",
    "    elif isinstance(df, (pl.DataFrame, pl.Series)):\n",
    "        df = df[idxs]\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df)} is not supported\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c4e57-5ef8-4803-bfd0-19af4313340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    subset = take_rows(series, np.array([0, 2]))\n",
    "    assert subset.shape[0] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135ff8a-9abc-48fa-8adb-ddbb65fbcf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_with_mask(\n",
    "    df: Union[Series, DataFrame, pd.Index, np.ndarray],\n",
    "    mask: Union[np.ndarray, pd.Series, pl_Series]\n",
    ") -> DataFrame:\n",
    "    if isinstance(df, (pd.DataFrame, pd.Series, pd.Index, np.ndarray)):\n",
    "        out = df[mask]\n",
    "    elif isinstance(df, (pl.DataFrame, pl.Series)):\n",
    "        out = df.filter(mask)  # type: ignore\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df)} is not supported\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49529350-f0b2-4416-a78a-4f67d27e293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_nan(s: Series) -> Series:\n",
    "    if isinstance(s, pd.Series):\n",
    "        out = s.isna()\n",
    "    elif isinstance(s, pl.Series):\n",
    "        out = s.is_nan()\n",
    "    else:\n",
    "        raise ValueError(f\"{type(s)} is not supported\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f13160-171f-4961-b13c-e58808c7983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    is_nan(pd.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "    np.array([True, False, True]),\n",
    ")\n",
    "if POLARS_INSTALLED:\n",
    "    np.testing.assert_equal(\n",
    "        is_nan(pl.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "        np.array([True, False, None]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb895f6f-f4f1-4e15-8b4e-34ab8593c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_none(s: Series) -> Series:\n",
    "    if isinstance(s, pd.Series):\n",
    "        out = is_nan(s)\n",
    "    elif isinstance(s, pl.Series):\n",
    "        out = s.is_null()\n",
    "    else:\n",
    "        raise ValueError(f\"{type(s)} is not supported\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2df1c-4779-49cf-97a3-8198723d4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    is_none(pd.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "    np.array([True, False, True]),\n",
    ")\n",
    "if POLARS_INSTALLED:\n",
    "    np.testing.assert_equal(\n",
    "        is_none(pl.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "        np.array([False, False, True]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19737f8-0898-4ee6-9f10-6a1152e6bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_nan_or_none(s: Series) -> Series:\n",
    "    return is_nan(s) | is_none(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139f563-0ea4-43c4-86d0-0d7cff621a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    is_nan_or_none(pd.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "    np.array([True, False, True]),\n",
    ")\n",
    "if POLARS_INSTALLED:\n",
    "    np.testing.assert_equal(\n",
    "        is_nan_or_none(pl.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "        np.array([True, False, True]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af783f-97a2-4af3-8b55-f24cb63d8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def vertical_concat(dfs: List[DataFrame]) -> DataFrame:\n",
    "    if not dfs:\n",
    "        raise ValueError(\"Can't concatenate empty list.\")\n",
    "    if isinstance(dfs[0], pd.DataFrame):\n",
    "        out = pd.concat(dfs)\n",
    "    elif isinstance(dfs[0], pl_DataFrame):\n",
    "        out = pl.concat(dfs)\n",
    "    else:\n",
    "        raise ValueError(f'Got list of unexpected types: {type(dfs[0])}.')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785253d8-46a6-4e5d-80dc-c013fdb33872",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    doubled = vertical_concat([series, series])\n",
    "    assert doubled.shape[0] == 2 * series.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da156ead-8920-4d09-9dc7-b4fd483b11e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def horizontal_concat(dfs: List[DataFrame]) -> DataFrame:\n",
    "    if not dfs:\n",
    "        raise ValueError(\"Can't concatenate empty list.\")\n",
    "    if isinstance(dfs[0], pd.DataFrame):\n",
    "        out = pd.concat(dfs, axis=1)\n",
    "    elif isinstance(dfs[0], pl_DataFrame):\n",
    "        out = pl.concat(dfs, how='horizontal')\n",
    "    else:\n",
    "        raise ValueError(f'Got list of unexpected types: {type(dfs[0])}.')        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ca91e-d2a9-4bbc-9ba3-0a5f56c8d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    renamer = {c: f'{c}_2' for c in series.columns}\n",
    "    if engine == 'pandas':\n",
    "        series2 = series.rename(columns=renamer)\n",
    "    elif engine == 'polars':\n",
    "        series2 = series.rename(renamer)\n",
    "    else: \n",
    "        raise ValueError(f\"{type(df)} is not supported\")\n",
    "    doubled = horizontal_concat([series, series2])\n",
    "    assert doubled.shape[1] == 2 * series.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5276cb-b14a-4435-b116-996e9cf241ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def copy_if_pandas(df: DataFrame, deep: bool = False) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.copy(deep=deep)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfab719-b261-4953-91eb-b5226ec72013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def join(\n",
    "    df1: DataFrame,\n",
    "    df2: DataFrame,\n",
    "    on: Union[str, List[str]],\n",
    "    how: str = 'inner'\n",
    ") -> DataFrame:\n",
    "    if isinstance(df1, pd.DataFrame):\n",
    "        out = df1.merge(df2, on=on, how=how)\n",
    "    elif isinstance(df1, pl.DataFrame):\n",
    "        out = df1.join(df2, on=on, how=how)  # type: ignore\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df1)} is not supported\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23563a68-16c9-4379-93d8-2cfaa2120109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def drop_index_if_pandas(df: DataFrame) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bca15-5dc4-4fea-96be-911b6afb6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rename(df: DataFrame, mapping: Dict[str, str]) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.rename(columns=mapping, copy=False)\n",
    "    elif isinstance(df, pl.DataFrame):\n",
    "        df = df.rename(mapping)\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df)} is not supported\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140cf59-6c61-4af6-82b9-874299ad3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sort(df: DataFrame, by: Union[str, List[str]]) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        out = df.sort_values(by)\n",
    "    elif isinstance(df, pl.DataFrame):\n",
    "        out = df.sort(by)\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df)} is not supported\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22459a37-d1ce-426c-8b69-846632794379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def offset_dates(\n",
    "    dates: Union[pd.Index, pl_Series],\n",
    "    freq: Union[int, str, BaseOffset],\n",
    "    n: int,\n",
    "):\n",
    "    if isinstance(dates, (pd.DatetimeIndex, pd.Series, pd.Index)) and isinstance(freq, (int, BaseOffset)):\n",
    "        out = dates + n * freq\n",
    "    elif isinstance(dates, pl_Series) and isinstance(freq, int):\n",
    "        out = dates + n * freq\n",
    "    elif isinstance(dates, pl_Series) and isinstance(freq, str):\n",
    "        freq_n, freq_offset = re.findall(r'(\\d+)(\\w+)', freq)[0]\n",
    "        total_n = int(freq_n) * n\n",
    "        out = dates.dt.offset_by(f'{total_n}{freq_offset}')\n",
    "    else:\n",
    "        raise ValueError(f\"Can't process the following combination {(type(dates), type(freq))}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c81ccf-4655-4cee-8940-004633d87f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def group_by(df: Union[Series, DataFrame], by, maintain_order=False):\n",
    "    if isinstance(df, (pd.Series, pd.DataFrame)):\n",
    "        out = df.groupby(by, observed=True, sort=not maintain_order)\n",
    "    if isinstance(df, (pl.Series, pl.DataFrame)):\n",
    "        if isinstance(df, pl_Series):\n",
    "            df = df.to_frame()\n",
    "        try:\n",
    "            out = df.group_by(by, maintain_order=maintain_order)\n",
    "        except AttributeError:\n",
    "            out = df.groupby(by, maintain_order=maintain_order)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d909cbb-dbb3-4860-af16-6f1dd399297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_in(s: Series, collection) -> Series:\n",
    "    if isinstance(s, pl_Series):\n",
    "        out = s.is_in(collection)\n",
    "    else:\n",
    "        out = s.isin(collection)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3c95d-9112-48c0-a104-c725a2390bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(is_in(pd.Series([1, 2, 3]), [1]), np.array([True, False, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d522a-a806-44ea-9c99-70059515ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "np.testing.assert_equal(is_in(pl.Series([1, 2, 3]), [1]), np.array([True, False, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bfc2f3-f571-4ea5-91aa-d3e4cc1a1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def value_cols_to_numpy(\n",
    "    df: DataFrame, id_col: str, time_col: str, target_col: str    \n",
    ") -> np.ndarray:\n",
    "    exclude_cols = [id_col, time_col, target_col]\n",
    "    value_cols = [target_col] + [col for col in df.columns if col not in exclude_cols]\n",
    "    data = to_numpy(df[value_cols])\n",
    "    if data.dtype not in (np.float32, np.float64):\n",
    "        data = data.astype(np.float32)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e059e1-8c6f-41b1-b3c0-4ca40adf09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_df(\n",
    "    df: DataFrame,\n",
    "    id_col: str,\n",
    "    time_col: str,\n",
    "    target_col: str\n",
    ") -> Tuple[Series, np.ndarray, np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "    \"\"\"Extract components from dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Input dataframe with id, times and target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ids : pandas or polars Serie\n",
    "        serie with the sorted unique ids present in the data.\n",
    "    last_times : numpy array\n",
    "        array with the last time for each serie.\n",
    "    data : numpy ndarray\n",
    "        2d array with target plus features values.\n",
    "    indptr : numpy ndarray\n",
    "        1d array with indices to the start and end of each serie.\n",
    "    sort_idxs : numpy array or None\n",
    "        array with the indices that would sort the original data.\n",
    "        If the data is already sorted this is `None`.            \n",
    "    \"\"\"\n",
    "    # validations\n",
    "    validate_format(df, id_col, time_col, target_col)\n",
    "\n",
    "    # ids\n",
    "    id_counts = counts_by_id(df, id_col)\n",
    "    uids = id_counts[id_col]\n",
    "\n",
    "    # indices\n",
    "    sizes = id_counts['counts'].to_numpy()\n",
    "    indptr = np.append(0, sizes.cumsum()).astype(np.int32)\n",
    "    last_idxs = indptr[1:] - 1\n",
    "\n",
    "    # data\n",
    "    data = value_cols_to_numpy(df, id_col, time_col, target_col)\n",
    "\n",
    "    # check if we need to sort\n",
    "    sort_idxs = maybe_compute_sort_indices(df, id_col, time_col)\n",
    "    if sort_idxs is not None:\n",
    "        data = data[sort_idxs]\n",
    "        last_idxs = sort_idxs[last_idxs]\n",
    "    times = df[time_col].to_numpy()[last_idxs]\n",
    "    return uids, times, data, indptr, sort_idxs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd1f31-05f4-4bda-9599-8f8922233c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataFrameProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        id_col: str = 'unique_id',\n",
    "        time_col: str = 'ds',\n",
    "        target_col: str = 'y',\n",
    "    ):\n",
    "        self.id_col = id_col\n",
    "        self.time_col = time_col\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def process(\n",
    "        self,\n",
    "        df: DataFrame\n",
    "    ) -> Tuple[Series, np.ndarray, np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "        return process_df(df, self.id_col, self.time_col, self.target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2dee9-d54d-4ff9-9279-b91fa4968758",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_features = ['static_0', 'static_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c7661-0c1a-43ef-a88e-da6288cdac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_static_features in [0, 2]:\n",
    "    series_pd = generate_series(1_000, n_static_features=n_static_features, equal_ends=False, engine='pandas')\n",
    "    for i in range(n_static_features):\n",
    "        series_pd[f'static_{i}'] = series_pd[f'static_{i}'].map(lambda x: f'x_{x}').astype('category')\n",
    "    scrambled_series_pd = series_pd.sample(frac=1.0)\n",
    "    dfp = DataFrameProcessor('unique_id', 'ds', 'y')\n",
    "    uids, times, data, indptr, _ = dfp.process(scrambled_series_pd)\n",
    "    test_eq(times, series_pd.groupby('unique_id', observed=True)['ds'].max().values)\n",
    "    test_eq(uids, np.sort(series_pd['unique_id'].unique()))\n",
    "    for i in range(n_static_features):\n",
    "        series_pd[f'static_{i}'] = series_pd[f'static_{i}'].cat.codes\n",
    "    test_eq(data, series_pd[['y'] + static_features[:n_static_features]].to_numpy())\n",
    "    test_eq(np.diff(indptr), series_pd.groupby('unique_id', observed=True).size().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c959fc-206e-4eec-a61b-76de3856468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "for n_static_features in [0, 2]:\n",
    "    series_pl = generate_series(1_000, n_static_features=n_static_features, equal_ends=False, engine='polars')\n",
    "    scrambled_series_pl = series_pl.sample(fraction=1.0, shuffle=True)\n",
    "    dfp = DataFrameProcessor('unique_id', 'ds', 'y')\n",
    "    uids, times, data, indptr, _ = dfp.process(scrambled_series_pl)\n",
    "    grouped = group_by(series_pl, 'unique_id')\n",
    "    test_eq(times, grouped.agg(pl.col('ds').max()).sort('unique_id')['ds'].to_numpy())\n",
    "    test_eq(uids, series_pl['unique_id'].unique().sort())\n",
    "    test_eq(data, series_pl.select(pl.col(c).map_batches(lambda s: s.to_physical()) for c in ['y'] + static_features[:n_static_features]).to_numpy())\n",
    "    test_eq(np.diff(indptr), grouped.count().sort('unique_id')['count'].to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
