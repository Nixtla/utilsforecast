{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9284ac-4d6c-42fc-8d05-13ff8fa7460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d96e02b-4e1b-4284-8808-58c7dbb1fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133caf6-09b0-4de3-b168-b7cff92040a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BaseOffset\n",
    "\n",
    "from utilsforecast.compat import DataFrame, Series, pl, pl_DataFrame, pl_Series\n",
    "from utilsforecast.validation import validate_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970c3e9-b00a-4485-a8de-26471d515e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq\n",
    "from nbdev import show_doc\n",
    "\n",
    "from utilsforecast.compat import POLARS_INSTALLED\n",
    "from utilsforecast.data import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688032bd-838d-4086-be34-d0b02590a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _polars_categorical_to_numerical(serie: pl_Series) -> pl_Series:\n",
    "    if serie.dtype == pl.Categorical:\n",
    "        serie = serie.to_physical()\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04df186-1663-45b9-90ed-cdec91a137fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_numpy(df: DataFrame) -> np.ndarray:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        cat_cols = [c for c, dtype in df.dtypes.items() if isinstance(dtype, pd.CategoricalDtype)]\n",
    "        if cat_cols:\n",
    "            df = df.copy(deep=False)\n",
    "            for col in cat_cols:\n",
    "                df[col] = df[col].cat.codes\n",
    "        df = df.to_numpy()\n",
    "    else:\n",
    "        try:\n",
    "            expr = pl.all().map_batches(_polars_categorical_to_numerical)\n",
    "        except AttributeError:\n",
    "            expr = pl.all().map(_polars_categorical_to_numerical)\n",
    "        df = df.select(expr).to_numpy(order='c')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73199e1f-2104-47c5-9415-07b20e8a61d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def counts_by_id(df: DataFrame, id_col: str) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        id_counts = df.groupby(id_col, observed=True).size()\n",
    "        if not id_counts.index.is_monotonic_increasing:\n",
    "            id_counts = id_counts.sort_index()\n",
    "        id_counts = id_counts.reset_index()\n",
    "        id_counts.columns = [id_col, 'counts']\n",
    "    else:\n",
    "        id_counts = df[id_col].value_counts().sort(id_col)\n",
    "    return id_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29656557-2fb3-420f-ba19-fdc118118ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def maybe_compute_sort_indices(\n",
    "    df: DataFrame, id_col: str, time_col: str\n",
    ") -> Optional[np.ndarray]:\n",
    "    \"\"\"Compute indices that would sort dataframe\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Input dataframe with id, times and target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array or None\n",
    "        Array with indices to sort the dataframe or None if it's already sorted.\n",
    "    \"\"\"\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        idx = pd.MultiIndex.from_frame(df[[id_col, time_col]])\n",
    "    else:\n",
    "        # this was faster than trying to build the multi index from polars\n",
    "        sort_idxs = df.select(pl.arg_sort_by([id_col, time_col]).alias('idx'))['idx']\n",
    "        idx = pd.Index(sort_idxs.to_numpy())\n",
    "    if idx.is_monotonic_increasing:\n",
    "        return None\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        sort_idxs = idx.argsort()\n",
    "    return sort_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc46c8b-8aeb-4a0f-be20-5db503cf03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assign_columns(df: DataFrame, names: Union[str, List[str]], values: Union[np.ndarray, pd.Series, pl_Series]) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df[names] = values\n",
    "    else:\n",
    "        is_scalar = isinstance(values, str) or not hasattr(values, '__len__')\n",
    "        if is_scalar:\n",
    "            assert isinstance(names, str)\n",
    "            vals: Union[pl_DataFrame, pl_Series, pl.Expr] = pl.lit(values).alias(names)\n",
    "        elif isinstance(values, pl_Series):\n",
    "            assert isinstance(names, str)\n",
    "            vals = values.alias(names)\n",
    "        else:\n",
    "            if isinstance(names, str):\n",
    "                names = [names]\n",
    "            vals = pl.from_numpy(values, schema=names)\n",
    "        df = df.with_columns(vals)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb147d-7aba-49d9-b741-aff36be7caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = ['pandas']\n",
    "if POLARS_INSTALLED:\n",
    "    engines.append('polars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb9058-3993-4881-82fa-4fbe874ab56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    x = np.random.rand(series.shape[0])    \n",
    "    series = assign_columns(series, 'x', x)\n",
    "    series = assign_columns(series, ['y', 'z'], np.vstack([x, x]).T)\n",
    "    series = assign_columns(series, 'ones', 1)\n",
    "    series = assign_columns(series, 'zeros', np.zeros(series.shape[0]))\n",
    "    series = assign_columns(series, 'as', 'a')\n",
    "    np.testing.assert_allclose(\n",
    "        series[['x', 'y', 'z']],\n",
    "        np.vstack([x, x, x]).T\n",
    "    )\n",
    "    np.testing.assert_equal(series['ones'], np.ones(series.shape[0]))\n",
    "    np.testing.assert_equal(series['as'], np.full(series.shape[0], 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e41bbb-a541-4957-8c28-7af820488f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def take_rows(df: Union[DataFrame, Series, np.ndarray], idxs: np.ndarray) -> DataFrame:\n",
    "    if isinstance(df, (pd.DataFrame, pd.Series)):\n",
    "        df = df.iloc[idxs]\n",
    "    else:\n",
    "        df = df[idxs]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c4e57-5ef8-4803-bfd0-19af4313340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    subset = take_rows(series, np.array([0, 2]))\n",
    "    assert subset.shape[0] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135ff8a-9abc-48fa-8adb-ddbb65fbcf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_with_mask(\n",
    "    df: Union[Series, DataFrame, pd.Index, np.ndarray],\n",
    "    mask: Union[np.ndarray, pd.Series, pl_Series]\n",
    ") -> DataFrame:\n",
    "    if isinstance(df, (pd.DataFrame, pd.Series, pd.Index, np.ndarray)):\n",
    "        out = df[mask]\n",
    "    else:\n",
    "        out = df.filter(mask)  # type: ignore\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49529350-f0b2-4416-a78a-4f67d27e293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_nan(s: Series) -> Series:\n",
    "    if isinstance(s, pd.Series):\n",
    "        out = s.isna()\n",
    "    else:\n",
    "        out = s.is_nan()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f13160-171f-4961-b13c-e58808c7983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    is_nan(pd.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "    np.array([True, False, True]),\n",
    ")\n",
    "if POLARS_INSTALLED:\n",
    "    np.testing.assert_equal(\n",
    "        is_nan(pl.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "        np.array([True, False, None]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb895f6f-f4f1-4e15-8b4e-34ab8593c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_none(s: Series) -> Series:\n",
    "    if isinstance(s, pd.Series):\n",
    "        out = is_nan(s)\n",
    "    else:\n",
    "        out = s.is_null()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2df1c-4779-49cf-97a3-8198723d4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    is_none(pd.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "    np.array([True, False, True]),\n",
    ")\n",
    "if POLARS_INSTALLED:\n",
    "    np.testing.assert_equal(\n",
    "        is_none(pl.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "        np.array([False, False, True]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19737f8-0898-4ee6-9f10-6a1152e6bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_nan_or_none(s: Series) -> Series:\n",
    "    return is_nan(s) | is_none(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139f563-0ea4-43c4-86d0-0d7cff621a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    is_nan_or_none(pd.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "    np.array([True, False, True]),\n",
    ")\n",
    "if POLARS_INSTALLED:\n",
    "    np.testing.assert_equal(\n",
    "        is_nan_or_none(pl.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "        np.array([True, False, True]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e7421-017d-49f9-bdd0-c59fc7556488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def match_if_categorical(s1: Union[Series, pd.Index], s2: Series) -> Tuple[Series, Series]:\n",
    "    if isinstance(s1.dtype, pd.CategoricalDtype):\n",
    "        if isinstance(s1, pd.Index):\n",
    "            cat1 = s1.categories\n",
    "        else:\n",
    "            cat1 = s1.cat.categories\n",
    "        if isinstance(s2.dtype, pd.CategoricalDtype):\n",
    "            cat2 = s2.cat.categories\n",
    "        else:\n",
    "            cat2 = s2.unique().astype(cat1.dtype)\n",
    "        missing = set(cat2) - set(cat1)\n",
    "        if missing:\n",
    "            # we assume the original is s1, so we extend its categories\n",
    "            new_dtype = pd.CategoricalDtype(categories=cat1.tolist() + sorted(missing))\n",
    "            s1 = s1.astype(new_dtype)\n",
    "            s2 = s2.astype(new_dtype)\n",
    "    elif isinstance(s1, pl_Series) and s1.dtype == pl.Categorical:\n",
    "        with pl.StringCache():\n",
    "            cat1 = s1.cat.get_categories()\n",
    "            if s2.dtype == pl.Categorical:\n",
    "                cat2 = s2.cat.get_categories()\n",
    "            else:\n",
    "                cat2 = s2.unique().sort().cast(cat1.dtype)\n",
    "            # populate cache, keep original categories first\n",
    "            pl.concat([cat1, cat2]).cast(pl.Categorical)\n",
    "            s1 = s1.cast(pl.Utf8).cast(pl.Categorical)\n",
    "            s2 = s2.cast(pl.Utf8).cast(pl.Categorical)\n",
    "    return s1, s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af783f-97a2-4af3-8b55-f24cb63d8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def vertical_concat(dfs: List[DataFrame], match_categories: bool = True) -> DataFrame:\n",
    "    if not dfs:\n",
    "        raise ValueError(\"Can't concatenate empty list.\")\n",
    "    if isinstance(dfs[0], pd.DataFrame):\n",
    "        cat_cols = [c for c, dtype in dfs[0].dtypes.items() if isinstance(dtype, pd.CategoricalDtype)]\n",
    "        if match_categories and cat_cols:\n",
    "            if len(dfs) > 2:\n",
    "                raise NotImplementedError('Categorical replacement for more than two dataframes')\n",
    "            assert len(dfs) == 2\n",
    "            df1, df2 = dfs\n",
    "            df1 = df1.copy(deep=False)\n",
    "            df2 = df2.copy(deep=False)            \n",
    "            for col in cat_cols:\n",
    "                s1, s2 = match_if_categorical(df1[col], df2[col])\n",
    "                df1[col] = s1\n",
    "                df2[col] = s2\n",
    "            dfs = [df1, df2]\n",
    "        out = pd.concat(dfs).reset_index(drop=True)\n",
    "    else:\n",
    "        all_cols = dfs[0].columns\n",
    "        cat_cols = [all_cols[i] for i, dtype in enumerate(dfs[0].dtypes) if dtype == pl.Categorical]\n",
    "        if match_categories and cat_cols:\n",
    "            if len(dfs) > 2:\n",
    "                raise NotImplementedError('Categorical replacement for more than two dataframes')\n",
    "            assert len(dfs) == 2\n",
    "            df1, df2 = dfs\n",
    "            for col in cat_cols:\n",
    "                s1, s2 = match_if_categorical(df1[col], df2[col])\n",
    "                df1 = df1.with_columns(s1)\n",
    "                df2 = df2.with_columns(s2)\n",
    "            dfs = [df1, df2]\n",
    "        out = pl.concat(dfs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c0461-3964-4c82-a406-9fb7ea624f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'x': ['a', 'b', 'c']}, dtype='category')\n",
    "df2 = pd.DataFrame({'x': ['f', 'b', 'a']}, dtype='category')\n",
    "pd.testing.assert_series_equal(\n",
    "    vertical_concat([df1,df2])['x'],\n",
    "    pd.Series(['a', 'b', 'c', 'f', 'b', 'a'], name='x', dtype=pd.CategoricalDtype(categories=['a', 'b', 'c', 'f']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ab374-90fc-4ba8-b442-797abc63d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "df1 = pl.DataFrame({'x': ['a', 'b', 'c']}, schema={'x': pl.Categorical})\n",
    "df2 = pl.DataFrame({'x': ['f', 'b', 'a']}, schema={'x': pl.Categorical})\n",
    "out = vertical_concat([df1,df2])['x']\n",
    "assert out.series_equal(pl.Series('x', ['a', 'b', 'c', 'f', 'b', 'a']))\n",
    "assert out.to_physical().series_equal(pl.Series('x', [0, 1, 2, 3, 1, 0]))\n",
    "assert out.cat.get_categories().series_equal(\n",
    "    pl.Series('x', ['a', 'b', 'c', 'f'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785253d8-46a6-4e5d-80dc-c013fdb33872",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    doubled = vertical_concat([series, series])\n",
    "    assert doubled.shape[0] == 2 * series.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da156ead-8920-4d09-9dc7-b4fd483b11e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def horizontal_concat(dfs: List[DataFrame]) -> DataFrame:\n",
    "    if not dfs:\n",
    "        raise ValueError(\"Can't concatenate empty list.\")\n",
    "    if isinstance(dfs[0], pd.DataFrame):\n",
    "        out = pd.concat(dfs, axis=1)\n",
    "    elif isinstance(dfs[0], pl_DataFrame):\n",
    "        out = pl.concat(dfs, how='horizontal')\n",
    "    else:\n",
    "        raise ValueError(f'Got list of unexpected types: {type(dfs[0])}.')        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ca91e-d2a9-4bbc-9ba3-0a5f56c8d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    renamer = {c: f'{c}_2' for c in series.columns}\n",
    "    if engine == 'pandas':\n",
    "        series2 = series.rename(columns=renamer)\n",
    "    else:\n",
    "        series2 = series.rename(renamer)\n",
    "    doubled = horizontal_concat([series, series2])\n",
    "    assert doubled.shape[1] == 2 * series.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5276cb-b14a-4435-b116-996e9cf241ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def copy_if_pandas(df: DataFrame, deep: bool = False) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.copy(deep=deep)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfab719-b261-4953-91eb-b5226ec72013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def join(\n",
    "    df1: Union[DataFrame, Series],\n",
    "    df2: Union[DataFrame, Series],\n",
    "    on: Union[str, List[str]],\n",
    "    how: str = 'inner'\n",
    ") -> DataFrame:\n",
    "    if isinstance(df1, (pd.Series, pl_Series)):\n",
    "        df1 = df1.to_frame()\n",
    "    if isinstance(df2, (pd.Series, pl_Series)):\n",
    "        df2 = df2.to_frame()\n",
    "    if isinstance(df1, pd.DataFrame):\n",
    "        out = df1.merge(df2, on=on, how=how)\n",
    "    else:\n",
    "        out = df1.join(df2, on=on, how=how)  # type: ignore\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23563a68-16c9-4379-93d8-2cfaa2120109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def drop_index_if_pandas(df: DataFrame) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bca15-5dc4-4fea-96be-911b6afb6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rename(df: DataFrame, mapping: Dict[str, str]) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.rename(columns=mapping, copy=False)\n",
    "    else:\n",
    "        df = df.rename(mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140cf59-6c61-4af6-82b9-874299ad3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sort(df: DataFrame, by: Optional[Union[str, List[str]]] = None) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        out = df.sort_values(by).reset_index(drop=True)\n",
    "    elif isinstance(df, (pd.Series, pd.Index)):\n",
    "        out = df.sort_values()\n",
    "        if isinstance(out, pd.Series):\n",
    "            out = out.reset_index(drop=True)\n",
    "    elif isinstance(df, pl_DataFrame):\n",
    "        out = df.sort(by)\n",
    "    else:\n",
    "        out = df.sort()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e0b1c-3770-4d8d-a8d0-63ed2bdf147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(\n",
    "    sort(pd.DataFrame({'x': [3, 1, 2]}), 'x'),\n",
    "    pd.DataFrame({'x': [1, 2, 3]})\n",
    ")\n",
    "pd.testing.assert_frame_equal(\n",
    "    sort(pd.DataFrame({'x': [3, 1, 2]}), ['x']),\n",
    "    pd.DataFrame({'x': [1, 2, 3]})\n",
    ")\n",
    "pd.testing.assert_series_equal(\n",
    "    sort(pd.Series([3, 1, 2])),\n",
    "    pd.Series([1, 2, 3])\n",
    ")\n",
    "pd.testing.assert_index_equal(\n",
    "    sort(pd.Index([3, 1, 2])),\n",
    "    pd.Index([1, 2, 3])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1c151-1f81-442d-9f32-d88ca85a5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "# TODO: replace with pl.testing.assert_frame_equal when it's released\n",
    "pd.testing.assert_frame_equal(\n",
    "    sort(pl.DataFrame({'x': [3, 1, 2]}), 'x').to_pandas(),\n",
    "    pd.DataFrame({'x': [1, 2, 3]}),\n",
    ")\n",
    "pd.testing.assert_frame_equal(\n",
    "    sort(pl.DataFrame({'x': [3, 1, 2]}), ['x']).to_pandas(),\n",
    "    pd.DataFrame({'x': [1, 2, 3]}),\n",
    ")\n",
    "pd.testing.assert_series_equal(\n",
    "    sort(pl.Series('x', [3, 1, 2])).to_pandas(),\n",
    "    pd.Series([1, 2, 3], name='x')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22459a37-d1ce-426c-8b69-846632794379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def offset_dates(\n",
    "    dates: Union[pd.Index, pl_Series],\n",
    "    freq: Union[int, str, BaseOffset],\n",
    "    n: int,\n",
    "):\n",
    "    if isinstance(dates, (pd.DatetimeIndex, pd.Series, pd.Index)) and isinstance(freq, (int, BaseOffset)):\n",
    "        out = dates + n * freq\n",
    "    elif isinstance(dates, pl_Series) and isinstance(freq, int):\n",
    "        out = dates + n * freq\n",
    "    elif isinstance(dates, pl_Series) and isinstance(freq, str):\n",
    "        freq_n, freq_offset = re.findall(r'(\\d+)(\\w+)', freq)[0]\n",
    "        total_n = int(freq_n) * n\n",
    "        out = dates.dt.offset_by(f'{total_n}{freq_offset}')\n",
    "    else:\n",
    "        raise ValueError(f\"Can't process the following combination {(type(dates), type(freq))}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c81ccf-4655-4cee-8940-004633d87f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def group_by(df: Union[Series, DataFrame], by, maintain_order=False):\n",
    "    if isinstance(df, (pd.Series, pd.DataFrame)):\n",
    "        out = df.groupby(by, observed=True, sort=not maintain_order)\n",
    "    else:\n",
    "        if isinstance(df, pl_Series):\n",
    "            df = df.to_frame()\n",
    "        try:\n",
    "            out = df.group_by(by, maintain_order=maintain_order)\n",
    "        except AttributeError:\n",
    "            out = df.groupby(by, maintain_order=maintain_order)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e3ff2c-9e70-46b3-9bf0-bbfcd339d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def group_by_agg(df: DataFrame, by, aggs, maintain_order=False) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        out = group_by(df, by, maintain_order).agg(aggs).reset_index()\n",
    "    else:\n",
    "        out = group_by(df, by, maintain_order).agg(*[getattr(pl.col(c), agg)() for c, agg in aggs.items()])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f92cd4-d3f7-4de1-b438-c3c5891c3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(\n",
    "    group_by_agg(pd.DataFrame({'x': [1, 1, 2], 'y': [1, 1, 1]}), 'x', {'y': 'sum'}),\n",
    "    pd.DataFrame({'x': [1, 2], 'y': [2, 1]})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cfc66-a218-498e-b674-96491f47a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "pd.testing.assert_frame_equal(\n",
    "    group_by_agg(pl.DataFrame({'x': [1, 1, 2], 'y': [1, 1, 1]}), 'x', {'y': 'sum'}, maintain_order=True).to_pandas(),\n",
    "    pd.DataFrame({'x': [1, 2], 'y': [2, 1]})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d909cbb-dbb3-4860-af16-6f1dd399297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_in(s: Series, collection) -> Series:\n",
    "    if isinstance(s, pl_Series):\n",
    "        out = s.is_in(collection)\n",
    "    else:\n",
    "        out = s.isin(collection)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3c95d-9112-48c0-a104-c725a2390bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(is_in(pd.Series([1, 2, 3]), [1]), np.array([True, False, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d522a-a806-44ea-9c99-70059515ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "np.testing.assert_equal(is_in(pl.Series([1, 2, 3]), [1]), np.array([True, False, False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717022e-2c6f-47dc-8b19-da069341b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def between(s: Series, lower: Series, upper: Series) -> Series:\n",
    "    if isinstance(s, pd.Series):\n",
    "        out = s.between(lower, upper)\n",
    "    else:\n",
    "        out = s.is_between(lower, upper)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca138b4-e771-4b8e-aa54-35dc37802d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    between(pd.Series([1, 2, 3]), pd.Series([0, 1, 4]), pd.Series([4, 1, 2])),\n",
    "    np.array([True, False, False]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c773bf-fe23-4428-84f6-c5afaefdad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "np.testing.assert_equal(\n",
    "    between(pl.Series([1, 2, 3]), pl.Series([0, 1, 4]), pl.Series([4, 1, 2])),\n",
    "    np.array([True, False, False]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667302bf-3b54-4298-8fcc-82cd6b12fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def fill_null(df: DataFrame, mapping: Dict[str, Any]) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        out = df.fillna(mapping)\n",
    "    else:\n",
    "        out = df.with_columns(*[pl.col(col).fill_null(v) for col, v in mapping.items()])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74993c58-0886-4290-ab90-8065651886c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_frame_equal(\n",
    "    fill_null(pd.DataFrame({'x': [1, np.nan], 'y': [np.nan, 2]}), {'x': 2, 'y': 1}),\n",
    "    pd.DataFrame({'x': [1, 2], 'y': [1, 2]}, dtype='float64')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d835a-f1dc-4c1a-be2d-e7dd5b9895ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "# TODO: replace with pl.testing.assert_frame_equal when it's released\n",
    "pd.testing.assert_frame_equal(\n",
    "    fill_null(pl.DataFrame({'x': [1, None], 'y': [None, 2]}), {'x': 2, 'y': 1}).to_pandas(),\n",
    "    pd.DataFrame({'x': [1, 2], 'y': [1, 2]})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d5993-1af2-4eb5-a60e-4cefa07624ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cast(s: Series, dtype: type) -> Series:\n",
    "    if isinstance(s, pd.Series):\n",
    "        s = s.astype(dtype)\n",
    "    else:\n",
    "        s = s.cast(dtype)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fb4cb1-87c7-4464-b09a-522d14b9896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.testing.assert_series_equal(\n",
    "    cast(pd.Series([1, 2, 3]), 'int16'),\n",
    "    pd.Series([1, 2, 3], dtype='int16')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8bf34-a8be-4e10-a239-f8357cf5fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "pd.testing.assert_series_equal(\n",
    "    cast(pl.Series('x', [1, 2, 3]), pl.Int16).to_pandas(),\n",
    "    pd.Series([1, 2, 3], name='x', dtype='int16')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bfc2f3-f571-4ea5-91aa-d3e4cc1a1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def value_cols_to_numpy(\n",
    "    df: DataFrame, id_col: str, time_col: str, target_col: str    \n",
    ") -> np.ndarray:\n",
    "    exclude_cols = [id_col, time_col, target_col]\n",
    "    value_cols = [target_col] + [col for col in df.columns if col not in exclude_cols]\n",
    "    data = to_numpy(df[value_cols])\n",
    "    if data.dtype not in (np.float32, np.float64):\n",
    "        data = data.astype(np.float32)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e059e1-8c6f-41b1-b3c0-4ca40adf09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_df(\n",
    "    df: DataFrame,\n",
    "    id_col: str,\n",
    "    time_col: str,\n",
    "    target_col: str\n",
    ") -> Tuple[Series, np.ndarray, np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "    \"\"\"Extract components from dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas or polars DataFrame\n",
    "        Input dataframe with id, times and target values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ids : pandas or polars Serie\n",
    "        serie with the sorted unique ids present in the data.\n",
    "    last_times : numpy array\n",
    "        array with the last time for each serie.\n",
    "    data : numpy ndarray\n",
    "        2d array with target plus features values.\n",
    "    indptr : numpy ndarray\n",
    "        1d array with indices to the start and end of each serie.\n",
    "    sort_idxs : numpy array or None\n",
    "        array with the indices that would sort the original data.\n",
    "        If the data is already sorted this is `None`.            \n",
    "    \"\"\"\n",
    "    # validations\n",
    "    validate_format(df, id_col, time_col, target_col)\n",
    "\n",
    "    # ids\n",
    "    id_counts = counts_by_id(df, id_col)\n",
    "    uids = id_counts[id_col]\n",
    "\n",
    "    # indices\n",
    "    sizes = id_counts['counts'].to_numpy()\n",
    "    indptr = np.append(0, sizes.cumsum()).astype(np.int32)\n",
    "    last_idxs = indptr[1:] - 1\n",
    "\n",
    "    # data\n",
    "    data = value_cols_to_numpy(df, id_col, time_col, target_col)\n",
    "\n",
    "    # check if we need to sort\n",
    "    sort_idxs = maybe_compute_sort_indices(df, id_col, time_col)\n",
    "    if sort_idxs is not None:\n",
    "        data = data[sort_idxs]\n",
    "        last_idxs = sort_idxs[last_idxs]\n",
    "    times = df[time_col].to_numpy()[last_idxs]\n",
    "    return uids, times, data, indptr, sort_idxs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd1f31-05f4-4bda-9599-8f8922233c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataFrameProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        id_col: str = 'unique_id',\n",
    "        time_col: str = 'ds',\n",
    "        target_col: str = 'y',\n",
    "    ):\n",
    "        self.id_col = id_col\n",
    "        self.time_col = time_col\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def process(\n",
    "        self,\n",
    "        df: DataFrame\n",
    "    ) -> Tuple[Series, np.ndarray, np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "        return process_df(df, self.id_col, self.time_col, self.target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2dee9-d54d-4ff9-9279-b91fa4968758",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_features = ['static_0', 'static_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c7661-0c1a-43ef-a88e-da6288cdac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_static_features in [0, 2]:\n",
    "    series_pd = generate_series(1_000, n_static_features=n_static_features, equal_ends=False, engine='pandas')\n",
    "    for i in range(n_static_features):\n",
    "        series_pd[f'static_{i}'] = series_pd[f'static_{i}'].map(lambda x: f'x_{x}').astype('category')\n",
    "    scrambled_series_pd = series_pd.sample(frac=1.0)\n",
    "    dfp = DataFrameProcessor('unique_id', 'ds', 'y')\n",
    "    uids, times, data, indptr, _ = dfp.process(scrambled_series_pd)\n",
    "    test_eq(times, series_pd.groupby('unique_id', observed=True)['ds'].max().values)\n",
    "    test_eq(uids, np.sort(series_pd['unique_id'].unique()))\n",
    "    for i in range(n_static_features):\n",
    "        series_pd[f'static_{i}'] = series_pd[f'static_{i}'].cat.codes\n",
    "    test_eq(data, series_pd[['y'] + static_features[:n_static_features]].to_numpy())\n",
    "    test_eq(np.diff(indptr), series_pd.groupby('unique_id', observed=True).size().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c959fc-206e-4eec-a61b-76de3856468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "for n_static_features in [0, 2]:\n",
    "    series_pl = generate_series(1_000, n_static_features=n_static_features, equal_ends=False, engine='polars')\n",
    "    scrambled_series_pl = series_pl.sample(fraction=1.0, shuffle=True)\n",
    "    dfp = DataFrameProcessor('unique_id', 'ds', 'y')\n",
    "    uids, times, data, indptr, _ = dfp.process(scrambled_series_pl)\n",
    "    grouped = group_by(series_pl, 'unique_id')\n",
    "    test_eq(times, grouped.agg(pl.col('ds').max()).sort('unique_id')['ds'].to_numpy())\n",
    "    test_eq(uids, series_pl['unique_id'].unique().sort())\n",
    "    test_eq(data, series_pl.select(pl.col(c).map_batches(lambda s: s.to_physical()) for c in ['y'] + static_features[:n_static_features]).to_numpy())\n",
    "    test_eq(np.diff(indptr), grouped.count().sort('unique_id')['count'].to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
