{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9284ac-4d6c-42fc-8d05-13ff8fa7460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d96e02b-4e1b-4284-8808-58c7dbb1fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133caf6-09b0-4de3-b168-b7cff92040a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BaseOffset\n",
    "\n",
    "from utilsforecast.compat import DataFrame, Series, pl, pl_DataFrame, pl_Series\n",
    "from utilsforecast.validation import validate_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970c3e9-b00a-4485-a8de-26471d515e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq\n",
    "from nbdev import show_doc\n",
    "\n",
    "from utilsforecast.compat import POLARS_INSTALLED\n",
    "from utilsforecast.data import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688032bd-838d-4086-be34-d0b02590a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _polars_categorical_to_numerical(serie: pl_Series) -> pl_Series:\n",
    "    if serie.dtype == pl.Categorical:\n",
    "        serie = serie.to_physical()\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc46c8b-8aeb-4a0f-be20-5db503cf03e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assign_columns(df: DataFrame, names: Union[str, List[str]], values: Union[np.ndarray, pd.Series, pl_Series]) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df[names] = values\n",
    "    else:\n",
    "        is_scalar = isinstance(values, str) or not hasattr(values, '__len__')\n",
    "        if is_scalar:\n",
    "            assert isinstance(names, str)\n",
    "            vals: Union[pl_DataFrame, pl_Series, pl.Expr] = pl.lit(values).alias(names)\n",
    "        elif isinstance(values, pl_Series):\n",
    "            assert isinstance(names, str)\n",
    "            vals = values.alias(names)\n",
    "        else:\n",
    "            if isinstance(names, str):\n",
    "                names = [names]\n",
    "            vals = pl.from_numpy(values, schema=names)\n",
    "        df = df.with_columns(vals)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb147d-7aba-49d9-b741-aff36be7caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = ['pandas']\n",
    "if POLARS_INSTALLED:\n",
    "    engines.append('polars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb9058-3993-4881-82fa-4fbe874ab56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    x = np.random.rand(series.shape[0])    \n",
    "    series = assign_columns(series, 'x', x)\n",
    "    series = assign_columns(series, ['y', 'z'], np.vstack([x, x]).T)\n",
    "    series = assign_columns(series, 'ones', 1)\n",
    "    series = assign_columns(series, 'zeros', np.zeros(series.shape[0]))\n",
    "    series = assign_columns(series, 'as', 'a')\n",
    "    np.testing.assert_allclose(\n",
    "        series[['x', 'y', 'z']],\n",
    "        np.vstack([x, x, x]).T\n",
    "    )\n",
    "    np.testing.assert_equal(series['ones'], np.ones(series.shape[0]))\n",
    "    np.testing.assert_equal(series['as'], np.full(series.shape[0], 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e41bbb-a541-4957-8c28-7af820488f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def take_rows(df: Union[DataFrame, Series], idxs: np.ndarray) -> DataFrame:\n",
    "    if isinstance(df, (pd.DataFrame, pd.Series)):\n",
    "        df = df.iloc[idxs]\n",
    "    else:\n",
    "        df = df[idxs]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c4e57-5ef8-4803-bfd0-19af4313340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    subset = take_rows(series, np.array([0, 2]))\n",
    "    assert subset.shape[0] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7135ff8a-9abc-48fa-8adb-ddbb65fbcf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_with_mask(\n",
    "    df: Union[Series, DataFrame, pd.Index],\n",
    "    mask: Union[np.ndarray, pd.Series, pl_Series]\n",
    ") -> DataFrame:\n",
    "    if isinstance(df, (pd.DataFrame, pd.Series, pd.Index)):\n",
    "        out = df[mask]\n",
    "    else:\n",
    "        out = df.filter(mask)  # type: ignore\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49529350-f0b2-4416-a78a-4f67d27e293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_nan(s: Series) -> Series:\n",
    "    if isinstance(s, pd.Series):\n",
    "        out = s.isna()\n",
    "    else:\n",
    "        out = s.is_nan()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f13160-171f-4961-b13c-e58808c7983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    is_nan(pd.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "    np.array([True, False, True]),\n",
    ")\n",
    "if POLARS_INSTALLED:\n",
    "    np.testing.assert_equal(\n",
    "        is_nan(pl.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "        np.array([True, False, None]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb895f6f-f4f1-4e15-8b4e-34ab8593c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_none(s: Series) -> Series:\n",
    "    if isinstance(s, pd.Series):\n",
    "        out = is_nan(s)\n",
    "    else:\n",
    "        out = s.is_null()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2df1c-4779-49cf-97a3-8198723d4818",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    is_none(pd.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "    np.array([True, False, True]),\n",
    ")\n",
    "if POLARS_INSTALLED:\n",
    "    np.testing.assert_equal(\n",
    "        is_none(pl.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "        np.array([False, False, True]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19737f8-0898-4ee6-9f10-6a1152e6bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_nan_or_none(s: Series) -> Series:\n",
    "    return is_nan(s) | is_none(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139f563-0ea4-43c4-86d0-0d7cff621a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    is_nan_or_none(pd.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "    np.array([True, False, True]),\n",
    ")\n",
    "if POLARS_INSTALLED:\n",
    "    np.testing.assert_equal(\n",
    "        is_nan_or_none(pl.Series([np.nan, 1.0, None])).to_numpy(),\n",
    "        np.array([True, False, True]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af783f-97a2-4af3-8b55-f24cb63d8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def vertical_concat(dfs: List[DataFrame]) -> DataFrame:\n",
    "    if not dfs:\n",
    "        raise ValueError(\"Can't concatenate empty list.\")\n",
    "    if isinstance(dfs[0], pd.DataFrame):\n",
    "        out = pd.concat(dfs)\n",
    "    elif isinstance(dfs[0], pl_DataFrame):\n",
    "        out = pl.concat(dfs)\n",
    "    else:\n",
    "        raise ValueError(f'Got list of unexpected types: {type(dfs[0])}.')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785253d8-46a6-4e5d-80dc-c013fdb33872",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    doubled = vertical_concat([series, series])\n",
    "    assert doubled.shape[0] == 2 * series.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da156ead-8920-4d09-9dc7-b4fd483b11e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def horizontal_concat(dfs: List[DataFrame]) -> DataFrame:\n",
    "    if not dfs:\n",
    "        raise ValueError(\"Can't concatenate empty list.\")\n",
    "    if isinstance(dfs[0], pd.DataFrame):\n",
    "        out = pd.concat(dfs, axis=1)\n",
    "    elif isinstance(dfs[0], pl_DataFrame):\n",
    "        out = pl.concat(dfs, how='horizontal')\n",
    "    else:\n",
    "        raise ValueError(f'Got list of unexpected types: {type(dfs[0])}.')        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ca91e-d2a9-4bbc-9ba3-0a5f56c8d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for engine in engines:\n",
    "    series = generate_series(2, engine=engine)\n",
    "    renamer = {c: f'{c}_2' for c in series.columns}\n",
    "    if engine == 'pandas':\n",
    "        series2 = series.rename(columns=renamer)\n",
    "    else:\n",
    "        series2 = series.rename(renamer)\n",
    "    doubled = horizontal_concat([series, series2])\n",
    "    assert doubled.shape[1] == 2 * series.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5276cb-b14a-4435-b116-996e9cf241ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def copy_if_pandas(df: DataFrame, deep: bool = False) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.copy(deep=deep)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfab719-b261-4953-91eb-b5226ec72013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def join(\n",
    "    df1: DataFrame,\n",
    "    df2: DataFrame,\n",
    "    on: Union[str, List[str]],\n",
    "    how: str = 'inner'\n",
    ") -> DataFrame:\n",
    "    if isinstance(df1, pd.DataFrame):\n",
    "        out = df1.merge(df2, on=on, how=how)\n",
    "    else:\n",
    "        out = df1.join(df2, on=on, how=how)  # type: ignore\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23563a68-16c9-4379-93d8-2cfaa2120109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def drop_index_if_pandas(df: DataFrame) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bca15-5dc4-4fea-96be-911b6afb6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rename(df: DataFrame, mapping: Dict[str, str]) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        df = df.rename(columns=mapping, copy=False)\n",
    "    else:\n",
    "        df = df.rename(mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140cf59-6c61-4af6-82b9-874299ad3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sort(df: DataFrame, by: Union[str, List[str]]) -> DataFrame:\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        out = df.sort_values(by)\n",
    "    else:\n",
    "        out = df.sort(by)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22459a37-d1ce-426c-8b69-846632794379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def offset_dates(\n",
    "    dates: Union[pd.Index, pl_Series],\n",
    "    freq: Union[int, str, BaseOffset],\n",
    "    n: int,\n",
    "):\n",
    "    if isinstance(dates, (pd.DatetimeIndex, pd.Series, pd.Index)) and isinstance(freq, (int, BaseOffset)):\n",
    "        out = dates + n * freq\n",
    "    elif isinstance(dates, pl_Series) and isinstance(freq, int):\n",
    "        out = dates + n * freq\n",
    "    elif isinstance(dates, pl_Series) and isinstance(freq, str):\n",
    "        freq_n, freq_offset = re.findall(r'(\\d+)(\\w+)', freq)[0]\n",
    "        total_n = int(freq_n) * n\n",
    "        out = dates.dt.offset_by(f'{total_n}{freq_offset}')\n",
    "    else:\n",
    "        raise ValueError(f\"Can't process the following combination {(type(dates), type(freq))}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c81ccf-4655-4cee-8940-004633d87f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def group_by(df: Union[Series, DataFrame], by, maintain_order=False):\n",
    "    if isinstance(df, (pd.Series, pd.DataFrame)):\n",
    "        out = df.groupby(by, observed=True, sort=not maintain_order)\n",
    "    else:\n",
    "        if isinstance(df, pl_Series):\n",
    "            df = df.to_frame()\n",
    "        try:\n",
    "            out = df.group_by(by, maintain_order=maintain_order)\n",
    "        except AttributeError:\n",
    "            out = df.groupby(by, maintain_order=maintain_order)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd1f31-05f4-4bda-9599-8f8922233c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataFrameProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        id_col: str = 'unique_id',\n",
    "        time_col: str = 'ds',\n",
    "        target_col: str = 'y',\n",
    "    ):\n",
    "        \"\"\"Class to  extract common structures from pandas and polars dataframes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        id_col : str (default='unique_id')\n",
    "            Column that identifies each serie.\n",
    "        time_col : str (default='ds')\n",
    "            Column that identifies each timestep, its values can be timestamps or integers.\n",
    "        target_col : str (default='y')\n",
    "            Column that contains the target.\n",
    "        \"\"\"\n",
    "        self.id_col = id_col\n",
    "        self.time_col = time_col\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def counts_by_id(self, df: DataFrame) -> DataFrame:\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            id_counts = df.groupby(self.id_col, observed=True).size()\n",
    "            id_counts = id_counts.reset_index()\n",
    "            id_counts.columns = [self.id_col, 'counts']\n",
    "        else:\n",
    "            id_counts = df[self.id_col].value_counts().sort(self.id_col)\n",
    "        return id_counts\n",
    "\n",
    "    def value_cols_to_numpy(self, df: DataFrame) -> np.ndarray:\n",
    "        exclude_cols = [self.id_col, self.time_col, self.target_col]\n",
    "        value_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "        # ensure target is the first column\n",
    "        value_cols = [self.target_col] + value_cols\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            dtypes = df.dtypes\n",
    "            cat_cols = [c for c in value_cols if isinstance(dtypes[c], pd.CategoricalDtype)]\n",
    "            if cat_cols:\n",
    "                df = df.copy(deep=False)\n",
    "                for col in cat_cols:\n",
    "                    df[col] = df[col].cat.codes\n",
    "            data = df[value_cols].to_numpy()\n",
    "        else:\n",
    "            try:\n",
    "                expr = pl.all().map_batches(_polars_categorical_to_numerical)\n",
    "            except AttributeError:\n",
    "                expr = pl.all().map(_polars_categorical_to_numerical)\n",
    "    \n",
    "            data = df[value_cols].select(expr).to_numpy()\n",
    "        return data\n",
    "\n",
    "    def maybe_compute_sort_indices(self, df: DataFrame) -> Optional[np.ndarray]:\n",
    "        \"\"\"Compute indices that would sort dataframe\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas or polars DataFrame\n",
    "            Input dataframe with id, times and target values.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        numpy array or None\n",
    "            Array with indices to sort the dataframe or None if it's already sorted.\n",
    "        \"\"\"        \n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            idx = pd.MultiIndex.from_arrays([df[self.id_col], df[self.time_col]])\n",
    "        else:\n",
    "            import polars as pl\n",
    "\n",
    "            sort_idxs = df.select(\n",
    "                pl.arg_sort_by([self.id_col, self.time_col]).alias(\"idx\")\n",
    "            )['idx'].to_numpy()\n",
    "            idx = pd.Index(sort_idxs)\n",
    "        if idx.is_monotonic_increasing:\n",
    "            return None\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "            sort_idxs = idx.argsort()\n",
    "        return sort_idxs    \n",
    "\n",
    "    def process(\n",
    "        self,\n",
    "        df: DataFrame\n",
    "    ) -> Tuple[Series, np.ndarray, np.ndarray, np.ndarray, Optional[np.ndarray]]:\n",
    "        \"\"\"Extract components from dataframe\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pandas or polars DataFrame\n",
    "            Input dataframe with id, times and target values.\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        ids : pandas or polars Serie\n",
    "            serie with the sorted unique ids present in the data.\n",
    "        last_times : numpy array\n",
    "            array with the last time for each serie.\n",
    "        data : numpy ndarray\n",
    "            1d array with target values.\n",
    "        indptr : numpy ndarray\n",
    "            1d array with indices to the start and end of each serie.\n",
    "        sort_idxs : numpy array or None\n",
    "            array with the indices that would sort the original data.\n",
    "            If the data is already sorted this is `None`.            \n",
    "        \"\"\"\n",
    "        # validations\n",
    "        validate_format(df, self.id_col, self.time_col, self.target_col)\n",
    "\n",
    "        # ids\n",
    "        id_counts = self.counts_by_id(df)\n",
    "        uids = id_counts[self.id_col]\n",
    "\n",
    "        # indices\n",
    "        indptr = np.append(\n",
    "            np.int64(0),\n",
    "            id_counts['counts'].to_numpy().cumsum().astype(np.int64),\n",
    "        )\n",
    "        last_idxs = indptr[1:] - 1        \n",
    "\n",
    "        # data\n",
    "        data = self.value_cols_to_numpy(df)\n",
    "        # ensure float dtype\n",
    "        if data.dtype not in (np.float32, np.float64):\n",
    "            data = data.astype(np.float32)\n",
    "        # ensure 2d\n",
    "        if data.ndim == 1:\n",
    "            data = data.reshape(-1, 1)\n",
    "\n",
    "        # check if we need to sort\n",
    "        sort_idxs = self.maybe_compute_sort_indices(df)\n",
    "        if sort_idxs is not None:\n",
    "            data = data[sort_idxs]\n",
    "            last_idxs = sort_idxs[last_idxs]\n",
    "        times = df[self.time_col].to_numpy()[last_idxs]\n",
    "        return uids, times, data, indptr, sort_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66521e-a4ed-40a7-a7c6-d3152928f69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/utilsforecast/blob/main/utilsforecast/processing.py#L197){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DataFrameProcessor\n",
       "\n",
       ">      DataFrameProcessor (id_col:str='unique_id', time_col:str='ds',\n",
       ">                          target_col:str='y')\n",
       "\n",
       "Class to  extract common structures from pandas and polars dataframes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/utilsforecast/blob/main/utilsforecast/processing.py#L197){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DataFrameProcessor\n",
       "\n",
       ">      DataFrameProcessor (id_col:str='unique_id', time_col:str='ds',\n",
       ">                          target_col:str='y')\n",
       "\n",
       "Class to  extract common structures from pandas and polars dataframes.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| id_col | str | unique_id | Column that identifies each serie. |\n",
       "| time_col | str | ds | Column that identifies each timestep, its values can be timestamps or integers. |\n",
       "| target_col | str | y | Column that contains the target. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DataFrameProcessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a78b9-0a96-4829-bc54-188500da12cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/utilsforecast/blob/main/utilsforecast/processing.py#L280){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DataFrameProcessor.process\n",
       "\n",
       ">      DataFrameProcessor.process\n",
       ">                                  (df:Union[pandas.core.frame.DataFrame,polars.\n",
       ">                                  dataframe.frame.DataFrame])\n",
       "\n",
       "Extract components from dataframe\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| df | Union | Input dataframe with id, times and target values. |\n",
       "| **Returns** | **Tuple** | **serie with the sorted unique ids present in the data.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/utilsforecast/blob/main/utilsforecast/processing.py#L280){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DataFrameProcessor.process\n",
       "\n",
       ">      DataFrameProcessor.process\n",
       ">                                  (df:Union[pandas.core.frame.DataFrame,polars.\n",
       ">                                  dataframe.frame.DataFrame])\n",
       "\n",
       "Extract components from dataframe\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| df | Union | Input dataframe with id, times and target values. |\n",
       "| **Returns** | **Tuple** | **serie with the sorted unique ids present in the data.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DataFrameProcessor.process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2dee9-d54d-4ff9-9279-b91fa4968758",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_features = ['static_0', 'static_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c7661-0c1a-43ef-a88e-da6288cdac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_static_features in [0, 2]:\n",
    "    series_pd = generate_series(1_000, n_static_features=n_static_features, equal_ends=False, engine='pandas')\n",
    "    for i in range(n_static_features):\n",
    "        series_pd[f'static_{i}'] = series_pd[f'static_{i}'].map(lambda x: f'x_{x}').astype('category')\n",
    "    scrambled_series_pd = series_pd.sample(frac=1.0)\n",
    "    dfp = DataFrameProcessor('unique_id', 'ds', 'y')\n",
    "    uids, times, data, indptr, _ = dfp.process(scrambled_series_pd)\n",
    "    test_eq(times, series_pd.groupby('unique_id', observed=True)['ds'].max().values)\n",
    "    test_eq(uids, np.sort(series_pd['unique_id'].unique()))\n",
    "    for i in range(n_static_features):\n",
    "        series_pd[f'static_{i}'] = series_pd[f'static_{i}'].cat.codes\n",
    "    test_eq(data, series_pd[['y'] + static_features[:n_static_features]].to_numpy())\n",
    "    test_eq(np.diff(indptr), series_pd.groupby('unique_id', observed=True).size().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c959fc-206e-4eec-a61b-76de3856468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| polars\n",
    "for n_static_features in [0, 2]:\n",
    "    series_pl = generate_series(1_000, n_static_features=n_static_features, equal_ends=False, engine='polars')\n",
    "    scrambled_series_pl = series_pl.sample(fraction=1.0, shuffle=True)\n",
    "    dfp = DataFrameProcessor('unique_id', 'ds', 'y')\n",
    "    uids, times, data, indptr, _ = dfp.process(scrambled_series_pl)\n",
    "    grouped = group_by(series_pl, 'unique_id')\n",
    "    test_eq(times, grouped.agg(pl.col('ds').max()).sort('unique_id')['ds'].to_numpy())\n",
    "    test_eq(uids, series_pl['unique_id'].unique().sort())\n",
    "    test_eq(data, series_pl.select(pl.col(c).map_batches(lambda s: s.to_physical()) for c in ['y'] + static_features[:n_static_features]).to_numpy())\n",
    "    test_eq(np.diff(indptr), grouped.count().sort('unique_id')['count'].to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
